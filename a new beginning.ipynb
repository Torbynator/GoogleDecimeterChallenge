{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a vewrsion of the original notebook. Instead of preparing the data by padding and masking smaller batches of time series of the trajectories are prepared and fed to the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for the GoogleDecimeterChallenge https://www.kaggle.com/competitions/smartphone-decimeter-2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also try to run it on google collab, works great only RAM is limited:\n",
    "https://colab.research.google.com/github/Torbynator/GoogleDecimeterChallenge/blob/main/main.ipynb#scrollTo=TOn-Can4C0YP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Only for google collab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install  kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
    "!kaggle competitions download -c smartphone-decimeter-2023\n",
    "!unzip /content/smartphone-decimeter-2023.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\t\n",
    "import folium\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "INPUT_PATH = 'sdc2023/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# test_input_data = []\n",
    "# test_gt_data = []\n",
    "\n",
    "# #iterate over all data files and store them in the respective arrays\n",
    "\n",
    "# #load test data\n",
    "# test_files = os.listdir(INPUT_PATH + \"test\")\n",
    "\n",
    "# for folder in test_files:\n",
    "#     smartphones = os.listdir(INPUT_PATH + \"test/\"+folder)\n",
    "#     for smartphone in smartphones:\n",
    "#         file =  \"/device_gnss.csv\"\n",
    "#         #store data in list while dropping first and 41st column (string data)\n",
    "#         test_input_data.append(pd.read_csv(INPUT_PATH + \"test/\" +folder+\"/\"+smartphone + file, usecols=[i for i in range(58) if i not in [0,40]], dtype=np.float32).to_numpy(dtype=np.float32).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train data\n",
    "\n",
    "def read_data(MAX_TRAJECTORIES):\n",
    "    train_files = os.listdir(INPUT_PATH + \"train\")\n",
    "    trajectory_count=0\n",
    "    used_columns = [\"utcTimeMillis\",\"RawPseudorangeMeters\", \"RawPseudorangeUncertaintyMeters\" ,\"SvPositionXEcefMeters\" ,\"SvPositionYEcefMeters\", \"SvPositionZEcefMeters\", \"IsrbMeters\"]\n",
    "    \n",
    "    train_input_data = []\n",
    "    train_gt_data = []\n",
    "\n",
    "    for folder in train_files:\n",
    "        smartphones = os.listdir(INPUT_PATH + \"train/\"+folder)\n",
    "        for smartphone in smartphones:\n",
    "            files = os.listdir(INPUT_PATH + \"train/\"+folder+\"/\"+smartphone)\n",
    "            for file in files:\n",
    "                if file.endswith(\".csv\"):\n",
    "                    if trajectory_count >= MAX_TRAJECTORIES:\n",
    "                        break   \n",
    "                    if \"gnss\" in file:\n",
    "                        #store data in list while dropping first and 41st column (string data), as well as (porbably mostly) empty columns\n",
    "                        #also all data points with the same timestep are seen as features of one timestep of a sample\n",
    "                        sample = pd.read_csv(INPUT_PATH + \"train/\" +folder+\"/\"+ smartphone+ \"/\" + file, usecols=used_columns, dtype=float).to_numpy(dtype=float)\n",
    "                        #correct PseudoRange with ISRB\n",
    "                        sample[:,1] = sample[:,1] + sample[:,6]\n",
    "                        train_input_data.append(sample[:,0:6].swapaxes(0,1))                    \n",
    "                    elif \"ground_truth\" in file:\n",
    "                        trajectory_count +=1\n",
    "                        #store data in list while dropping first and 2nd column (string data),(probably mostly) empty columns\n",
    "                        train_gt_data.append(pd.read_csv(INPUT_PATH + \"train/\"+folder+\"/\" + smartphone+ \"/\" + file,  usecols=[i for i in range(9) if i not in [0,1]], dtype=float).to_numpy(dtype=float).swapaxes(0,1).tolist())\n",
    "                        print(f\"read in {trajectory_count} samples\")\n",
    "\n",
    "    #delete IRSB column\n",
    "    #del train_input_data[:][6]\n",
    "\n",
    "    #replace NaN values with 0\n",
    "    train_input_data = [[[0 if math.isnan(x) else x for x in timestep] for timestep in sample ] for sample in train_input_data]\n",
    "\n",
    "    return train_input_data, train_gt_data\n",
    "\n",
    "def read_imu_data(gnss_data_sorted_not_batched, MAX_TRAJECTORIES):\n",
    "    train_files = os.listdir(INPUT_PATH + \"train\")\n",
    "    trajectory_count=0\n",
    "    used_columns_IMU = [\"MessageType\",\"utcTimeMillis\",\"MeasurementX\",\"MeasurementY\",\"MeasurementZ\"]\n",
    "    imu_data = []\n",
    "    \n",
    "    for folder in train_files:\n",
    "        smartphones = os.listdir(INPUT_PATH + \"train/\"+folder)\n",
    "        for smartphone in smartphones:\n",
    "            files = os.listdir(INPUT_PATH + \"train/\"+folder+\"/\"+smartphone)\n",
    "            for file in files:\n",
    "                if file.endswith(\".csv\"):\n",
    "                    if trajectory_count >= MAX_TRAJECTORIES:\n",
    "                        break   \n",
    "                    if \"imu\" in file:\n",
    "                        #calculate accelerometer and gyro average measurement, sum and variance between gnss timesteps and store them in array with timesteps of gnss measurements\n",
    "                        #timestep of the calculated values is the later timestep of the used gnss timesteps\n",
    "                        #calculated values will later be added to the train data as features at the corresponding timesteps\n",
    "                        sample = pd.read_csv(INPUT_PATH + \"train/\" +folder+\"/\"+ smartphone+ \"/\" + file, usecols=used_columns_IMU).to_numpy()\n",
    "                        gnss_samples = gnss_data_sorted_not_batched[trajectory_count]\n",
    "                        sample_calc = []\n",
    "                        \n",
    "                        sample_iterator = 0\n",
    "                        measurement = sample[0]\n",
    "                        for gnss_step in gnss_samples:                            \n",
    "                            acc_values = [[],[],[]]\n",
    "                            gyro_values = [[],[],[]]\n",
    "                            while measurement[1] < gnss_step[0]:\n",
    "                                if \"Acc\" in measurement[0]:\n",
    "                                    acc_values[0].append(measurement[2])\n",
    "                                    acc_values[1].append(measurement[3])\n",
    "                                    acc_values[2].append(measurement[4])\n",
    "                                elif \"Gyr\" in measurement[0]:\n",
    "                                    gyro_values[0].append(measurement[2])\n",
    "                                    gyro_values[1].append(measurement[3])\n",
    "                                    gyro_values[2].append(measurement[4])\n",
    "                                sample_iterator += 1 \n",
    "                                measurement = sample[sample_iterator]    \n",
    "                                \n",
    "                            if any(acc_values) and any(gyro_values):  \n",
    "                                acc_average = [np.mean(acc_values[0]), np.mean(acc_values[1]), np.mean(acc_values[2])]\n",
    "                                acc_variance = [np.var(acc_values[0]), np.var(acc_values[1]), np.var(acc_values[2])]\n",
    "                                #acc_sum = [np.sum(acc_values[0]), np.sum(acc_values[1]), np.sum(acc_values[2])]\n",
    "                                gyro_average = [np.mean(gyro_values[0]), np.mean(gyro_values[1]), np.mean(gyro_values[2])]\n",
    "                                gyro_variance = [np.var(gyro_values[0]), np.var(gyro_values[1]), np.var(gyro_values[2])]\n",
    "                                #gyro_sum = [np.sum(gyro_values[0]), np.sum(gyro_values[1]), np.sum(gyro_values[2])]\n",
    "                                #sample_calc.append([acc_average[0], acc_average[1], acc_average[2], acc_variance[0], acc_variance[1], acc_variance[2], acc_sum[0], acc_sum[1], acc_sum[2], gyro_average[0], gyro_average[1], gyro_average[2], gyro_variance[0], gyro_variance[1], gyro_variance[2], gyro_sum[0], gyro_sum[1], gyro_sum[2]])\n",
    "                                sample_calc.append([acc_average[0], acc_average[1], acc_average[2], acc_variance[0], acc_variance[1], acc_variance[2], gyro_average[0], gyro_average[1], gyro_average[2], gyro_variance[0], gyro_variance[1], gyro_variance[2]])\n",
    "                            else:\n",
    "                                #sample_calc.append([0]*18)\n",
    "                                sample_calc.append([0,9.81,0,0,0,0,0,0,0,0,0,0])\n",
    "                        imu_data.append(np.array(sample_calc).swapaxes(0,1))\n",
    "                        trajectory_count +=1\n",
    "                        print(f\"read in {trajectory_count} samples\")\n",
    "    return imu_data\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as preprocess\n",
    "\n",
    "\n",
    "\n",
    "def normalize_data(data, identifier):\n",
    "    '''normalize data and return the scaler objects\n",
    "    normalizes data to be roughly between 0 and 1\n",
    "    or sometimes -1 and 1 in manner that makes the scaled data interpretable\n",
    "    \n",
    "    Args:\n",
    "    data to be normalized\n",
    "    type of data, to use standard predifenied normalization methods, since the type of data is knwon\n",
    "\n",
    "    Returns:\n",
    "    normalized data and scaler\n",
    "    '''\n",
    "    normalized_data = []\n",
    "    scaler = -1 #initialize undefined scaler\n",
    "\n",
    "    #differentiate which data comes is\n",
    "    if identifier == \"gnss\":\n",
    "        print(\"normalizing gnss data\")\n",
    "        #utc time gets ignored\n",
    "        #pseudorange is scaled (x-18*10^6m)/10^7m (satellites are at 20*10^6m orbital height. received signals dont go over 30*10^6m)\n",
    "        #pseudorange uncertainty is scaled by 25m (a typically high value)\n",
    "        #satellite postion is scaled by 20*10^6m which is a orbital heigth\n",
    "        for dataset in data:\n",
    "            normalized_feature = []\n",
    "            for i, feature in enumerate(np.array(dataset)):\n",
    "                if i == 1: #raw pseudorange-lsrb\n",
    "                    feature = (feature-18*10**6)/10000000\n",
    "                if i == 2:\n",
    "                    feature = feature/25\n",
    "                if i == 3 or i == 4 or i == 5: #satellite position\n",
    "                    feature = feature/20000000\n",
    "                normalized_feature.append(feature)\n",
    "            normalized_feature = np.array(normalized_feature).swapaxes(0,1).tolist()\n",
    "            normalized_data.append(normalized_feature)\n",
    "    \n",
    "\n",
    "    elif identifier == \"IMU\":\n",
    "        #acceleration average gets scaled by 9.81m/s^2\n",
    "        #gravity gets taken into account in y-direction\n",
    "        #everything else gets ignored, since the data is already in a sensible range\n",
    "        print(\"normalizing IMU data\")\n",
    "        for dataset in data:\n",
    "            normalized_feature = []\n",
    "            for i, feature in enumerate(np.array(dataset)):\n",
    "                if i == 0 or i ==2:\n",
    "                    feature = feature/9.81\n",
    "                if i == 1:\n",
    "                    feature = feature/9.81-1\n",
    "                normalized_feature.append(feature)\n",
    "            normalized_feature = np.array(normalized_feature).swapaxes(0,1)\n",
    "            print(normalized_feature.shape)\n",
    "            normalized_feature = normalized_feature.tolist()\n",
    "            normalized_data.append(normalized_feature)\n",
    "\n",
    "    elif identifier == \"gt\":\n",
    "        print(\"normalizing gt data\")\n",
    "        #latitude and longitude are scaled by 180°\n",
    "        #altitude is scaled by 12800m (flight level 420, the highest commercial flight level)\n",
    "        #speed is scaled by the speed of sound (343m/s)\n",
    "        #accuracy gets ignored\n",
    "        #bearing degrees are scaled by 360°\n",
    "        #utc time gets ignored\n",
    "        for dataset in data:\n",
    "            normalized_feature = []\n",
    "            for i, feature in enumerate(np.array(dataset)):\n",
    "                if i == 0 or i == 1: #latitude and longitude\n",
    "                    feature = feature/180\n",
    "                if i == 2: #altitude\n",
    "                    feature = feature/12800\n",
    "                if i == 3: #speed\n",
    "                    feature = feature/343\n",
    "                if i == 5: #bearing\n",
    "                    feature = feature/360\n",
    "                normalized_feature.append(feature)\n",
    "            normalized_feature = np.array(normalized_feature).swapaxes(0,1).tolist()\n",
    "            normalized_data.append(normalized_feature)\n",
    "\n",
    "    \n",
    "    else:\n",
    "        print(\"normalizing arbitrary data\")\n",
    "        scaler = preprocess.MinMaxScaler()\n",
    "        for sample in data:\n",
    "            data_range = []\n",
    "            normalized_data.append(scaler.fit_transform(sample))\n",
    "        normalized_data=np.array(normalized_data)\n",
    "\n",
    "    \n",
    "\n",
    "    return normalized_data    \n",
    "    \n",
    "    \n",
    "    # old function\n",
    "    # #normalize data\n",
    "    # print(\"normalizing data\")\n",
    "    # scaler = preprocess.MinMaxScaler()\n",
    "    # train_input_data_padded_normalized = []\n",
    "    # for sample in train_input_data_padded:\n",
    "    #     data_range = []\n",
    "    #     train_input_data_padded_normalized.append(scaler.fit_transform(sample))\n",
    "    # train_input_data_padded_normalized=np.array(train_input_data_padded_normalized)\n",
    "\n",
    "    # gt_scaler = preprocess.MinMaxScaler()\n",
    "    # train_gt_data_padded_normalized = []\n",
    "    # for sample in train_gt_data_padded:\n",
    "    #     data_range = []\n",
    "    #     train_gt_data_padded_normalized.append(gt_scaler.fit_transform(sample))\n",
    "    # train_gt_data_padded_normalized=np.array(train_gt_data_padded_normalized)\n",
    "\n",
    "    # return train_input_data_padded_normalized, train_gt_data_padded_normalized, scaler, gt_scaler\n",
    "    \n",
    "\n",
    "def unnormalize(data, identifier):\n",
    "    '''unnormalize data\n",
    "    that was previously normalized with the normalize_data function\n",
    "\n",
    "    Args:\n",
    "    data to be unnormalized\n",
    "    type of data, to use standard predifenied normalization methods, since the type of data is knwon\n",
    "\n",
    "    Returns:\n",
    "    unnormalized data\n",
    "    '''\n",
    "\n",
    "    unnormalized_data = []\n",
    "    scaler = -1 #initialize undefined scaler\n",
    "\n",
    "    #differentiate which data comes is\n",
    "    if identifier == \"gnss\":\n",
    "        print(\"unnormalizing gnss data\")\n",
    "        #utc time gets ignored\n",
    "        #pseudorange is scaled (x-18*10^6m)/10^7m (satellites are at 20*10^6m orbital height. received signals dont go over 30*10^6m)\n",
    "        #pseudorange uncertainty is scaled by 25m (a typically high value)\n",
    "        #satellite postion is scaled by 20*10^6m which is a orbital heigth\n",
    "        for dataset in data:\n",
    "            unnormalized_feature = []\n",
    "            for i, feature in enumerate(np.array(dataset)):\n",
    "                if i == 1: #raw pseudorange-lsrb\n",
    "                    feature = feature*10000000+18*10**6\n",
    "                if i == 2:\n",
    "                    feature = feature*25\n",
    "                if i == 3 or i == 4 or i == 5: #satellite position\n",
    "                    feature = feature*20000000\n",
    "                unnormalized_feature.append(feature)\n",
    "            unnormalized_feature = np.array(unnormalized_feature).tolist()\n",
    "            unnormalized_data.append(unnormalized_feature)\n",
    "\n",
    "    elif identifier == \"IMU\":\n",
    "        #acceleration average gets scaled by 9.81m/s^2\n",
    "        #gravity gets taken into account in y-direction\n",
    "        #everything else gets ignored, since the data is already in a sensible range\n",
    "        print(\"unnormalizing IMU data\")\n",
    "        for dataset in data:\n",
    "            unnormalized_feature = []\n",
    "            for i, feature in enumerate(np.array(dataset)):\n",
    "                if i == 0 or i ==2:\n",
    "                    feature = feature*9.81\n",
    "                if i == 1:\n",
    "                    feature = (feature+1)*9.81\n",
    "                unnormalized_feature.append(feature)\n",
    "            unnormalized_feature = np.array(unnormalized_feature).tolist()\n",
    "            unnormalized_data.append(unnormalized_feature)\n",
    "\n",
    "    elif identifier == \"gt\":\n",
    "        print(\"unnormalizing gt data\")\n",
    "        #latitude and longitude are scaled by 180°\n",
    "        #altitude is scaled by 12800m (flight level 420, the highest commercial flight level)\n",
    "        #speed is scaled by the speed of sound (343m/s)\n",
    "        #accuracy gets ignored\n",
    "        #bearing degrees are scaled by 360°\n",
    "        #utc time gets ignored\n",
    "        for dataset in data:\n",
    "            unnormalized_feature = []\n",
    "            for i, feature in enumerate(np.array(dataset)):\n",
    "                if i == 0 or i == 1: #latitude and longitude\n",
    "                    feature = feature*180\n",
    "                if i == 2: #altitude\n",
    "                    feature = feature*12800\n",
    "                if i == 3: #speed\n",
    "                    feature = feature*343\n",
    "                if i == 5: #bearing\n",
    "                    feature = feature*360\n",
    "                unnormalized_feature.append(feature)\n",
    "            unnormalized_feature = np.array(unnormalized_feature).tolist()\n",
    "            unnormalized_data.append(unnormalized_feature)\n",
    "\n",
    "    else:\n",
    "        print(\"unnormalizing arbitrary data\")\n",
    "        scaler = preprocess.MinMaxScaler()\n",
    "        for sample in data:\n",
    "            data_range = []\n",
    "            unnormalized_data.append(scaler.inverse_transform(sample))\n",
    "        unnormalized_data=np.array(unnormalized_data)\n",
    "\n",
    "    return unnormalized_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIME_SERIES_SIZE = 50\n",
    "\n",
    "def sort_data(TIME_SERIES_SIZE, train_input_data, train_gt_data, MAX_TRAJECTORIES, validation_split,batch_size,number_of_features=None):\n",
    "    '''sort gnss data of same time step into one line and prepare batches of time series of size TIME_SERIES_SIZE\n",
    "    also pad the data to the same length and add IMU data to the train data\n",
    "\n",
    "    Args:\n",
    "    TIME_SERIES_SIZE: size of the time series\n",
    "    train_input_data: input data\n",
    "    train_gt_data: ground truth data\n",
    "    MAX_TRAJECTORIES: maximum number of trajectories to be read in\n",
    "    number_of_features: number of features in the data, if not given, it is calculated from the data\n",
    "\n",
    "    Returns:\n",
    "    train_data: tf dataset of prepared timeseries of the input data and ground truth data\n",
    "    validation_data: tf dataset of prepared timeseries of the input data and ground truth data\n",
    "    '''\n",
    "\n",
    "    #move all features with the same timestamp to one line \n",
    "    for sample in range(len(train_input_data)):\n",
    "        matches = 0\n",
    "        print(f\"sample {sample+1} sorted\")\n",
    "        timesteps = 0\n",
    "        for step in range(len(train_input_data[sample])):\n",
    "            if step != 0:\n",
    "                if train_input_data[sample][step-matches][0] == train_input_data[sample][step-1-matches][0]:\n",
    "                    train_input_data[sample][step-1-matches].extend(train_input_data[sample][step-matches][1:])\n",
    "                    train_input_data[sample].pop(step-matches)\n",
    "                    matches +=1\n",
    "                else:\n",
    "                    timesteps+=1\n",
    "\n",
    "\n",
    "    #read in imu data and add it to the train data\n",
    "    print(\"reading imu data\")\n",
    "    IMU_data = read_imu_data(train_input_data, MAX_TRAJECTORIES)\n",
    "    IMU_data = normalize_data(IMU_data, \"IMU\")\n",
    "\n",
    "    #pad input data\n",
    "    print(\"padding train data\")\n",
    "    if number_of_features == None:\n",
    "        max_features = max([len(timestep) for sample in train_input_data for timestep in sample])\n",
    "    else:\n",
    "        max_features = number_of_features\n",
    "\n",
    "\n",
    "    train_input_data_padded = [tf.keras.preprocessing.sequence.pad_sequences(sample,value=0, padding=\"post\", dtype=np.float32, maxlen=max_features).tolist() for sample in train_input_data]\n",
    "    #train_input_data_padded = np.array(train_input_data_padded)\n",
    "\n",
    "    del train_input_data\n",
    "    \n",
    "    #insert IMU data at the end of train data\n",
    "    print(\"inserting IMU data\")\n",
    "    for i, sample in enumerate(train_input_data_padded):\n",
    "        for j, timestep in enumerate(sample):\n",
    "            timestep.extend(IMU_data[i][j])\n",
    "    #train_input_data_padded = np.concatenate((train_input_data_padded, IMU_data_batched), axis=2)\n",
    "    del IMU_data\n",
    "\n",
    "    #remove timestamp\n",
    "    for i in range(len(train_input_data_padded)):\n",
    "        for j in range(len(train_input_data_padded[i])):\n",
    "            train_input_data_padded[i][j].pop(0)\n",
    "    for i in range(len(train_gt_data)):\n",
    "        for j in range(len(train_gt_data[i])):\n",
    "            train_gt_data[i][j].pop(6)\n",
    "\n",
    "    #preparte one tf dataset of prepared timeseries of the input data\n",
    "    train_input_data_batches = [tf.keras.utils.timeseries_dataset_from_array(sample, gt_sample, TIME_SERIES_SIZE, sequence_stride=1, sampling_rate=1, batch_size=batch_size) for train_sample, gt_sample in zip(train_input_data_padded, train_gt_data)]\n",
    "\n",
    "    #split data into training and validation data\n",
    "    if validation_split == 0 or validation_split==None:\n",
    "        validation_data_batched = None\n",
    "\n",
    "        train_input_data_batched = train_input_data_batches[0]\n",
    "        for i in range(1,len(train_input_data_batches)):\n",
    "            train_input_data_batched = train_input_data_batched.concatenate(train_input_data_batches[i])\n",
    "\n",
    "        del train_input_data_padded, train_input_data_batches\n",
    "    else:\n",
    "        train_input_data_batches, validation_data_batches = train_test_split(train_input_data_batches, test_size=validation_split)\n",
    "\n",
    "        train_input_data_batched = train_input_data_batches[0]\n",
    "        for i in range(1,len(train_input_data_batches)):\n",
    "            train_input_data_batched = train_input_data_batched.concatenate(train_input_data_batches[i])\n",
    "\n",
    "        validation_data_batched = validation_data_batches[0]\n",
    "        for i in range(1,len(validation_data_batches)):\n",
    "            validation_data_batched = validation_data_batched.concatenate(validation_data_batches[i])\n",
    "\n",
    "        del train_input_data_padded, train_input_data_batches, train_gt_data, validation_data_batches\n",
    "\n",
    "    # train_gt_data_batches = [tf.keras.utils.timeseries_dataset_from_array(sample, None, TIME_SERIES_SIZE, sequence_stride=1, sampling_rate=1, batch_size=None) for sample in train_gt_data]\n",
    "    # train_gt_data_batched = train_gt_data_batches[0]\n",
    "    # for i in range(1,len(train_gt_data_batches)):\n",
    "    #     train_gt_data_batched = train_gt_data_batched.concatenate(train_gt_data_batches[i])\n",
    "\n",
    "    #del train_gt_data, train_gt_data_batches\n",
    "\n",
    "\n",
    "    # #prepare batches of time series of size TIME_SERIES_SIZE\n",
    "    # print(\"batching data\")\n",
    "    # train_input_data_batched = [sample[i:i+TIME_SERIES_SIZE] for sample in train_input_data for i in range(0,len(sample)-TIME_SERIES_SIZE)]\n",
    "    # train_gt_data_batched = [sample[i:i+TIME_SERIES_SIZE] for sample in train_gt_data for i in range(0,len(sample)-TIME_SERIES_SIZE)]\n",
    "    # IMU_data_batched = [sample[i:i+TIME_SERIES_SIZE] for sample in IMU_data for i in range(0,len(sample)-TIME_SERIES_SIZE)]\n",
    "    # IMU_data_batched = np.array(IMU_data_batched)\n",
    "\n",
    " \n",
    "\n",
    "    # #convert to right data format\n",
    "    # train_gt_data_padded = [tf.keras.preprocessing.sequence.pad_sequences(sample, value=0,padding=\"post\", dtype=np.float64, maxlen=max_features_gt) for sample in train_gt_data_batched]\n",
    "    # train_gt_data_padded = np.array(train_gt_data_padded)\n",
    "    # del train_gt_data, train_gt_data_batched\n",
    "\n",
    "    # print(train_input_data_padded.shape)\n",
    "    # print(train_gt_data_padded.shape)\n",
    "\n",
    "    # if(train_input_data_padded.shape[0] > train_gt_data_padded.shape[0]):\n",
    "    #     train_input_data_padded = train_input_data_padded[:train_gt_data_padded.shape[0]]\n",
    "    # elif(train_input_data_padded.shape[0] < train_gt_data_padded.shape[0]):\n",
    "    #     train_gt_data_padded = train_gt_data_padded[:train_input_data_padded.shape[0]]\n",
    "\n",
    "    # print(train_input_data_padded.shape)\n",
    "    # print(train_gt_data_padded.shape)\n",
    "    \n",
    "\n",
    "    #cut off unix time, as it is no longer needed, but yields very high values\n",
    "    #return train_input_data_padded[:,:,1:], train_gt_data_padded[:,:,:6]\n",
    "    return train_input_data_batched, validation_data_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(lat1, lon1, lat2, lon2):  # generally used geo measurement function\n",
    "    R = 6378.137; # Radius of earth in KM\n",
    "    dLat = lat2 * np.pi / 180 - lat1 * np.pi / 180\n",
    "    dLon = lon2 * np.pi / 180 - lon1 * np.pi / 180\n",
    "    a = np.sin(dLat/2) * np.sin(dLat/2) + np.cos(lat1 * np.pi / 180) * np.cos(lat2 * np.pi / 180) *  np.sin(dLon/2) * np.sin(dLon/2)\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = R * c\n",
    "    return d * 10000; #decimeters\n",
    "\n",
    "\n",
    "class DecimeterError(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(DecimeterError, self).__init__()\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "    \n",
    "    def on_training_begin(self, logs=None):\n",
    "        super().on_training_begin(logs)\n",
    "    \n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        super().on_batch_begin(batch, logs)\n",
    "\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        super().on_batch_end(batch, logs)\n",
    "\n",
    "\n",
    "    def on_training_end(self, epoch, logs=None):\n",
    "        super().on_training_end(epoch, logs)\n",
    "        ly_pred = self.model.predict(train_input_data_padded_normalized)\n",
    "        ly_true = train_gt_data_padded_normalized\n",
    "        ly_pred = np.array([gt_scaler.inverse_transform(sample) for sample in ly_pred])\n",
    "        ly_true = np.array([gt_scaler.inverse_transform(sample) for sample in ly_true])\n",
    "        error = measure(ly_pred[:,:,0], ly_pred[:,:,1], ly_true[:,:,0], ly_true[:,:,1])\n",
    "        total_avg_error = np.mean(error)\n",
    "        print(f\"decimeter error: {total_avg_error}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "SAMPLES = 30\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "def objective(trial):\n",
    "    global train_input_data_padded_normalized, train_gt_data_padded_normalized, scaler\n",
    "    TIME_SERIES_SIZE = trial.suggest_int(\"TIME_SERIES_SIZE\", 3, 50)\n",
    "    train_input_data, train_gt_data = read_data(SAMPLES)\n",
    "    train_gt_data_normalized = normalize_data(train_gt_data, \"gt\")\n",
    "    train_input_data_normalized = normalize_data(train_input_data, \"gnss\")\n",
    "    train_data, validation_data = sort_data(TIME_SERIES_SIZE, train_input_data_normalized, train_gt_data_normalized, SAMPLES, VALIDATION_SPLIT, BATCH_SIZE)\n",
    "    del train_input_data, train_gt_data, train_input_data_normalized, train_gt_data_normalized\n",
    "    #train_input_data_padded_normalized, train_gt_data_padded_normalized, scaler, gt_scaler = normalize_data(train_input_data_padded, train_gt_data_padded)\n",
    "\n",
    "    print(\"creating model\")\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"tanh\", \"relu\", \"linear\"])\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0, input_shape=(train_input_data_padded_normalized.shape[1], train_input_data_padded_normalized.shape[2])))\n",
    "    for i in range(n_layers-1):\n",
    "        model.add(LSTM(trial.suggest_int(f\"n_units_l{i}\", 10, 500), activation=activation, return_sequences=True))\n",
    "    model.add(LSTM(trial.suggest_int(f\"n_units_l{n_layers-1}\", 10, 500), activation=activation))\n",
    "    model.add(Dense(train_gt_data_padded_normalized.shape[2], activation=\"linear\"))\n",
    "\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate), loss=\"MeanSquaredError\")\n",
    "\n",
    "    print(f\"training model with {TIME_SERIES_SIZE} timesteps, {n_layers} layers, {activation} activation, {learning_rate} learning rate\")\n",
    "    history = model.fit(train_input_data_padded_normalized, train_gt_data_padded_normalized, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.1, callbacks=[PlotLossesKeras(), DecimeterError()], verbose=1)\n",
    "    #return validation score as indicator for the model quality\n",
    "    print(history.history[\"val_loss\"][-1])\n",
    "    return history.history[\"val_loss\"][-1]\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"optuna_results\"\n",
    "study_name = \"LSTM for GNSS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "save_study = optuna.create_study(study_name=study_name, storage=f\"sqlite:///{save_path}/{study_name}.db\")\n",
    "save_study.add_trials(study.trials)\n",
    "study.trials_dataframe().to_csv(f\"{save_path}/{study_name}.csv\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TIME_SERIES_SIZE': 11, 'n_layers': 3, 'activation': 'relu', 'n_units_l0': 95, 'n_units_l1': 18, 'n_units_l2': 100, 'learning_rate': 1.8400133435737296e-05}\n"
     ]
    }
   ],
   "source": [
    "loaded_study = optuna.load_study(study_name=study_name, storage=f\"sqlite:///{save_path}/{study_name}.db\")\n",
    "print(loaded_study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    0.013, max:    0.030, cur:    0.013)\n",
      "\tvalidation       \t (min:    0.013, max:    0.015, cur:    0.013)\n",
      "\u001b[1m1031/1031\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - loss: 0.0131 - val_loss: 0.0135\n",
      "0.013487953692674637\n"
     ]
    }
   ],
   "source": [
    "#train model with best params\n",
    "SAMPLES = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "params = loaded_study.best_params\n",
    "\n",
    "TIME_SERIES_SIZE = params[\"TIME_SERIES_SIZE\"]\n",
    "train_input_data, train_gt_data = read_data(SAMPLES)\n",
    "train_gt_data_normalized = normalize_data(train_gt_data, \"gt\")\n",
    "train_input_data_normalized = normalize_data(train_input_data, \"gnss\")\n",
    "train_data, validation_data = sort_data(TIME_SERIES_SIZE, train_input_data_normalized, train_gt_data_normalized, SAMPLES, VALIDATION_SPLIT, BATCH_SIZE)\n",
    "del train_input_data, train_gt_data, train_input_data_normalized, train_gt_data_normalized\n",
    "    \n",
    "\n",
    "\n",
    "n_layers = params[\"n_layers\"]\n",
    "activation = params[\"activation\"]\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Masking(mask_value=0, input_shape=(iter(train_data).next()[0].shape[1], iter(train_data).next()[0].shape[2])))\n",
    "for i in range(n_layers-1):\n",
    "    model.add(LSTM(params[f\"n_units_l{i}\"] , activation=activation, return_sequences=True))\n",
    "model.add(LSTM(params[f\"n_units_l{n_layers-1}\"], activation=activation))\n",
    "model.add(Dense(iter(train_data).next()[1].shape[1], activation=\"linear\"))    \n",
    "\n",
    "learning_rate = params[\"learning_rate\"]\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate), loss=\"MeanSquaredError\")\n",
    "print(model.summary())\n",
    "history = model.fit(train_data, epochs=EPOCHS, validation_data=validation_data, callbacks=[PlotLossesKeras(), DecimeterError()], verbose=1)\n",
    "#return validation score as indicator for the model quality\n",
    "print(history.history[\"val_loss\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in 1 samples\n",
      "normalizing gt data\n",
      "normalizing gnss data\n",
      "(None, 11, 267)\n",
      "sample 1 sorted\n",
      "reading imu data\n",
      "read in 1 samples\n",
      "normalizing IMU data\n",
      "(1300, 12)\n",
      "padding train data\n",
      "inserting IMU data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_30\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_30\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">267</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">137,940</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">47,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">606</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking_30 (\u001b[38;5;33mMasking\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m267\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_88 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m95\u001b[0m)         │       \u001b[38;5;34m137,940\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_89 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │         \u001b[38;5;34m8,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_90 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m47,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m606\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">583,064</span> (2.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m583,064\u001b[0m (2.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">194,354</span> (759.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m194,354\u001b[0m (759.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">388,710</span> (1.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m388,710\u001b[0m (1.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "[[ 0.21128266 -0.5946919   0.0126818   0.05115046  0.09868661  0.5244501 ]\n",
      " [ 0.21323842 -0.5796717   0.00943107  0.0512765   0.09780248  0.5097438 ]\n",
      " [ 0.21333073 -0.55944204  0.00686159  0.05003836  0.09536204  0.49256825]\n",
      " ...\n",
      " [ 0.1985786  -0.60732865  0.00737704  0.05086059  0.10136891  0.53191465]\n",
      " [ 0.20514853 -0.60056096  0.00785772  0.05004808  0.10048676  0.5326419 ]\n",
      " [ 0.2015067  -0.59165514  0.00832681  0.05093677  0.09982491  0.51957273]]\n",
      "unnormalizing gt data\n",
      "unnormalizing gt data\n",
      "(1, 1299, 6)\n",
      "(1290, 3)\n",
      "(1299, 3)\n"
     ]
    }
   ],
   "source": [
    "# visulaize trajectory on map\n",
    "path_data = read_data(1)\n",
    "\n",
    "gt_data_normalized = normalize_data(path_data[1], \"gt\")\n",
    "gnss_data_normalized = normalize_data(path_data[0], \"gnss\")\n",
    "print(model.input_shape)\n",
    "input_data,_  = sort_data(TIME_SERIES_SIZE, gnss_data_normalized, gt_data_normalized, 1,None,BATCH_SIZE, model.input_shape[2]-11)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "prediction = model.predict(input_data)\n",
    "print(prediction)\n",
    "prediction = np.array(unnormalize(prediction, \"gt\"))\n",
    "gt = np.array([unnormalize(sample, \"gt\") for sample in gt_data_normalized])\n",
    "print(gt.shape)\n",
    "\n",
    "predicted_path = prediction[:,0:3]\n",
    "gt_path = gt[0,:,0:3]\n",
    "\n",
    "print(predicted_path.shape)\n",
    "print(gt_path.shape)\n",
    "#plot it on a map\n",
    "\n",
    "\n",
    "m = folium.Map(location=[predicted_path[0,0], predicted_path[0,1]], zoom_start=25, max_zoom=35)\n",
    "\n",
    "for i in range(len(predicted_path)-1):\n",
    "    folium.PolyLine([[predicted_path[i,0], predicted_path[i,1]], [predicted_path[i+1,0], predicted_path[i+1,1]]], color=\"blue\").add_to(m)\n",
    "    folium.PolyLine([[gt_path[i,0], gt_path[i,1]], [gt_path[i+1,0], gt_path[i+1,1]]], color=\"red\").add_to(m)\n",
    "\n",
    "folium.Marker([predicted_path[-1,0], predicted_path[-1,1]], popup=f\"predicted: {predicted_path[-1,0]}, {predicted_path[-1,1]}\", icon=folium.Icon(color=\"red\")).add_to(m)\n",
    "folium.Marker([gt_path[-1,0], gt_path[-1,1]], popup=f\"gt: {gt_path[-1,0]}, {gt_path[-1,1]}\", icon=folium.Icon(color=\"red\")).add_to(m)\n",
    "\n",
    "m.save(\"map.html\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test für Idioten\n",
    "c = np.arange(24).reshape(2,3,4)\n",
    "print(c.shape)\n",
    "for r in c :\n",
    "    print(r)\n",
    "\n",
    "c = c.swapaxes(1,2).swapaxes(2,0)\n",
    "for r in c:\n",
    "    print(r)\n",
    "print(c.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
