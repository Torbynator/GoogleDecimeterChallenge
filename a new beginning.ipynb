{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a vewrsion of the original notebook. Instead of preparing the data by padding and masking smaller batches of time series of the trajectories are prepared and fed to the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for the GoogleDecimeterChallenge https://www.kaggle.com/competitions/smartphone-decimeter-2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also try to run it on google collab, works great only RAM is limited:\n",
    "https://colab.research.google.com/github/Torbynator/GoogleDecimeterChallenge/blob/main/main.ipynb#scrollTo=TOn-Can4C0YP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Only for google collab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install  kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
    "!kaggle competitions download -c smartphone-decimeter-2023\n",
    "!unzip /content/smartphone-decimeter-2023.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\t\n",
    "import folium\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking, Flatten, Input, Add\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "INPUT_PATH = 'sdc2023/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# test_input_data = []\n",
    "# test_gt_data = []\n",
    "\n",
    "# #iterate over all data files and store them in the respective arrays\n",
    "\n",
    "# #load test data\n",
    "# test_files = os.listdir(INPUT_PATH + \"test\")\n",
    "\n",
    "# for folder in test_files:\n",
    "#     smartphones = os.listdir(INPUT_PATH + \"test/\"+folder)\n",
    "#     for smartphone in smartphones:\n",
    "#         file =  \"/device_gnss.csv\"\n",
    "#         #store data in list while dropping first and 41st column (string data)\n",
    "#         test_input_data.append(pd.read_csv(INPUT_PATH + \"test/\" +folder+\"/\"+smartphone + file, usecols=[i for i in range(58) if i not in [0,40]], dtype=np.float32).to_numpy(dtype=np.float32).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecef2llo(x,y,z):\n",
    "    '''calculates latitude, longitude and altitude from x,y,z coordinates\n",
    "\n",
    "    Args:\n",
    "        x (float): x coordinate in meters\n",
    "        y (float): y coordinate in meters\n",
    "        z (float): z coordinate in meters\n",
    "\n",
    "    Returns:\n",
    "        float: latitude in degrees\n",
    "        float: longitude in degrees\n",
    "        float: altitude in meters\n",
    "    '''\n",
    "    a = 6378137.0 #in meters\n",
    "    b = 6356752.314245 #in meters\n",
    "\n",
    "    f = (a - b) / a\n",
    "    f_inv = 1.0 / f\n",
    "\n",
    "    e_sq = f * (2 - f)                       \n",
    "    eps = e_sq / (1.0 - e_sq)\n",
    "\n",
    "    p = math.sqrt(x * x + y * y)\n",
    "    q = math.atan2((z * a), (p * b))\n",
    "\n",
    "    sin_q = math.sin(q)\n",
    "    cos_q = math.cos(q)\n",
    "\n",
    "    sin_q_3 = sin_q * sin_q * sin_q\n",
    "    cos_q_3 = cos_q * cos_q * cos_q\n",
    "\n",
    "    phi = math.atan2((z + eps * b * sin_q_3), (p - e_sq * a * cos_q_3))\n",
    "    lam = math.atan2(y, x)\n",
    "\n",
    "    v = a / math.sqrt(1.0 - e_sq * math.sin(phi) * math.sin(phi))\n",
    "    h   = (p / math.cos(phi)) - v\n",
    "\n",
    "    lat = math.degrees(phi)\n",
    "    lon = math.degrees(lam)\n",
    "\n",
    "    return lat, lon, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train data\n",
    "\n",
    "def read_data(MAX_TRAJECTORIES):\n",
    "    train_files = os.listdir(INPUT_PATH + \"train\")\n",
    "    trajectory_count=0\n",
    "    used_columns = [\"utcTimeMillis\",\"PseudorangeRateMetersPerSecond\", \"RawPseudorangeMeters\", \"RawPseudorangeUncertaintyMeters\" ,\"SvPositionXEcefMeters\" ,\"SvPositionYEcefMeters\", \"SvPositionZEcefMeters\",\"IsrbMeters\",\"IonosphericDelayMeters\",\"TroposphericDelayMeters\", \"WlsPositionXEcefMeters\",\"WlsPositionYEcefMeters\",\"WlsPositionZEcefMeters\"]\n",
    "    used_columns_gt = [\"LatitudeDegrees\", \"LongitudeDegrees\"]\n",
    "\n",
    "    train_input_data = []\n",
    "    train_gt_data = []\n",
    "\n",
    "    for folder in train_files:\n",
    "        smartphones = os.listdir(INPUT_PATH + \"train/\"+folder)\n",
    "        for smartphone in smartphones:\n",
    "            files = os.listdir(INPUT_PATH + \"train/\"+folder+\"/\"+smartphone)\n",
    "            #random_augmentation_value = np.random.uniform(-1,-0.2)\n",
    "            for file in files:\n",
    "                if file.endswith(\".csv\"):\n",
    "                    if trajectory_count >= MAX_TRAJECTORIES:\n",
    "                        break   \n",
    "                    if \"gnss\" in file:\n",
    "                        #store data in list while dropping first and 41st column (string data), as well as (porbably mostly) empty columns\n",
    "                        #also all data points with the same timestep are seen as features of one timestep of a sample\n",
    "                        sample = pd.read_csv(INPUT_PATH + \"train/\" +folder+\"/\"+ smartphone+ \"/\" + file, usecols=used_columns, dtype=np.float64).to_numpy(dtype=np.float64)\n",
    "                        #correct PseudoRange with ISRB\n",
    "                        sample[:,2] = sample[:,2] + sample[:,7]\n",
    "                        sample = np.delete(sample, 7,1)\n",
    "                        #calculate latitude, longitude and altitude from ecef sattelite coordinates\n",
    "                        ecef = sample[:,4:7]\n",
    "                        lla = np.array([ecef2llo(x,y,z) for x,y,z in ecef])\n",
    "                        sample = np.delete(sample, [4,5,6],1)\n",
    "                        sample = np.concatenate((sample, lla), axis=1)\n",
    "                        #calculate latitude, longitude and altitude from ecef coordinates\n",
    "                        ecef = sample[:,6:9]\n",
    "                        lla = np.array([ecef2llo(x,y,z) for x,y,z in ecef])\n",
    "                        sample = np.delete(sample, [6,7,8],1)\n",
    "                        sample = np.concatenate((sample, lla), axis=1)\n",
    "\n",
    "                        train_input_data.append(sample.swapaxes(0,1).copy()) \n",
    "\n",
    "                        # #do some data augmentation by adding the same datawith the coordinates multiplied by by a random value between -1 and 0\n",
    "                        # sample[:,3:5] = sample[:,3:5]*random_augmentation_value\n",
    "                        # sample[:,6:8] = sample[:,6:8]*random_augmentation_value\n",
    "                        # train_input_data.append(sample.swapaxes(0,1))\n",
    "                        \n",
    "                        \n",
    "                                           \n",
    "                    elif \"ground_truth\" in file:\n",
    "                        trajectory_count +=1\n",
    "                        #store data in list while dropping first and 2nd column (string data),(probably mostly) empty columns\n",
    "                        gt  = np.array(pd.read_csv(INPUT_PATH + \"train/\"+folder+\"/\" + smartphone+ \"/\" + file,  usecols=used_columns_gt, dtype=np.float64).to_numpy(dtype=np.float64).swapaxes(0,1).tolist())\n",
    "                        train_gt_data.append(gt)\n",
    "                        # #append the same data multiplied by the random value\n",
    "                        # train_gt_data.append(gt*random_augmentation_value)\n",
    "                        print(f\"read in {trajectory_count} samples\")\n",
    "\n",
    "    #replace NaN values with 0\n",
    "    train_input_data = [[[0 if math.isnan(x) else x for x in timestep] for timestep in sample ] for sample in train_input_data]\n",
    "\n",
    "    return train_input_data, train_gt_data\n",
    "\n",
    "def read_imu_data(gnss_data_sorted_not_batched, MAX_TRAJECTORIES):\n",
    "    train_files = os.listdir(INPUT_PATH + \"train\")\n",
    "    trajectory_count=0\n",
    "    used_columns_IMU = [\"MessageType\",\"utcTimeMillis\",\"MeasurementX\",\"MeasurementY\",\"MeasurementZ\"]\n",
    "    imu_data = []\n",
    "    \n",
    "    for folder in train_files:\n",
    "        smartphones = os.listdir(INPUT_PATH + \"train/\"+folder)\n",
    "        for smartphone in smartphones:\n",
    "            files = os.listdir(INPUT_PATH + \"train/\"+folder+\"/\"+smartphone)\n",
    "            for file in files:\n",
    "                if file.endswith(\".csv\"):\n",
    "                    if trajectory_count >= MAX_TRAJECTORIES:\n",
    "                        break   \n",
    "                    if \"imu\" in file:\n",
    "                        #calculate accelerometer and gyro average measurement, sum and variance between gnss timesteps and store them in array with timesteps of gnss measurements\n",
    "                        #timestep of the calculated values is the later timestep of the used gnss timesteps\n",
    "                        #calculated values will later be added to the train data as features at the corresponding timesteps\n",
    "                        sample = pd.read_csv(INPUT_PATH + \"train/\" +folder+\"/\"+ smartphone+ \"/\" + file, usecols=used_columns_IMU).to_numpy()\n",
    "                        gnss_samples = gnss_data_sorted_not_batched[trajectory_count]\n",
    "                        sample_calc = []\n",
    "                        \n",
    "                        sample_iterator = 0\n",
    "                        measurement = sample[0]\n",
    "                        for gnss_step in gnss_samples:                            \n",
    "                            acc_values = [[],[],[]]\n",
    "                            gyro_values = [[],[],[]]\n",
    "                            while measurement[1] < gnss_step[0]:\n",
    "                                if \"Acc\" in measurement[0]:\n",
    "                                    acc_values[0].append(measurement[2])\n",
    "                                    acc_values[1].append(measurement[3])\n",
    "                                    acc_values[2].append(measurement[4])\n",
    "                                elif \"Gyr\" in measurement[0]:\n",
    "                                    gyro_values[0].append(measurement[2])\n",
    "                                    gyro_values[1].append(measurement[3])\n",
    "                                    gyro_values[2].append(measurement[4])\n",
    "                                sample_iterator += 1 \n",
    "                                try:\n",
    "                                    measurement = sample[sample_iterator]  \n",
    "                                except IndexError:\n",
    "                                    break  \n",
    "                                \n",
    "                            if any(acc_values) and any(gyro_values):  \n",
    "                                acc_average = [np.mean(acc_values[0]), np.mean(acc_values[1]), np.mean(acc_values[2])]\n",
    "                                acc_variance = [np.var(acc_values[0]), np.var(acc_values[1]), np.var(acc_values[2])]\n",
    "                                #acc_sum = [np.sum(acc_values[0]), np.sum(acc_values[1]), np.sum(acc_values[2])]\n",
    "                                gyro_average = [np.mean(gyro_values[0]), np.mean(gyro_values[1]), np.mean(gyro_values[2])]\n",
    "                                gyro_variance = [np.var(gyro_values[0]), np.var(gyro_values[1]), np.var(gyro_values[2])]\n",
    "                                #gyro_sum = [np.sum(gyro_values[0]), np.sum(gyro_values[1]), np.sum(gyro_values[2])]\n",
    "                                #sample_calc.append([acc_average[0], acc_average[1], acc_average[2], acc_variance[0], acc_variance[1], acc_variance[2], acc_sum[0], acc_sum[1], acc_sum[2], gyro_average[0], gyro_average[1], gyro_average[2], gyro_variance[0], gyro_variance[1], gyro_variance[2], gyro_sum[0], gyro_sum[1], gyro_sum[2]])\n",
    "                                sample_calc.append([acc_average[0], acc_average[1], acc_average[2], acc_variance[0], acc_variance[1], acc_variance[2], gyro_average[0], gyro_average[1], gyro_average[2], gyro_variance[0], gyro_variance[1], gyro_variance[2]])\n",
    "                            else:\n",
    "                                #sample_calc.append([0]*18)\n",
    "                                sample_calc.append([0,9.81,0,0,0,0,0,0,0,0,0,0])\n",
    "                        imu_data.append(np.array(sample_calc).swapaxes(0,1))\n",
    "                        trajectory_count +=1\n",
    "                        print(f\"read in {trajectory_count} samples\")\n",
    "    return imu_data\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as preprocess\n",
    "\n",
    "\n",
    "\n",
    "def normalize_data(data, identifier):\n",
    "    '''normalize data and return the scaler objects\n",
    "    normalizes data to be roughly between 0 and 1\n",
    "    or sometimes -1 and 1 in manner that makes the scaled data interpretable\n",
    "    \n",
    "    Args:\n",
    "    data to be normalized\n",
    "    type of data, to use standard predifenied normalization methods, since the type of data is knwon\n",
    "\n",
    "    Returns:\n",
    "    normalized data and scaler\n",
    "    '''\n",
    "    normalized_data = []\n",
    "    scaler = -1 #initialize undefined scaler\n",
    "\n",
    "    #differentiate which data comes is\n",
    "    if identifier == \"gnss\":\n",
    "        print(\"normalizing gnss data\")\n",
    "        #utc time gets ignored\n",
    "        #pseudorange is scaled (x-18*10^6m)/10^7m (satellites are at 20*10^6m orbital height. received signals dont go over 30*10^6m)\n",
    "        #pseudorange uncertainty is scaled by 25m (a typically high value)\n",
    "        #satellite postion is scaled by 20*10^6m which is a orbital heigth\n",
    "        for dataset in data:\n",
    "            normalized_feature = []\n",
    "            for i, feature in enumerate(np.array(dataset)):\n",
    "                if i == 1: #PseudorangeRate\n",
    "                    feature = feature/800\n",
    "                if i == 2: #raw pseudorange-lsrb\n",
    "                    feature = (feature-18*10**6)/10000000\n",
    "                if i == 3: #pseudorange uncertainty\n",
    "                    feature = feature/25\n",
    "                if i == 4: #ionospheric delay\n",
    "                    feature = feature/16\n",
    "                if i == 5: #tropospheric delay\n",
    "                    feature = feature/60\n",
    "                if i in [6,7]: #satellite position\n",
    "                    feature = feature/180\n",
    "                if i == 8: #satellite height\n",
    "                    feature = feature/(30*10**6)\n",
    "                if i in [9,10]: #wls position\n",
    "                    #feature = feature/6378137  \n",
    "                    feature = feature#/180\n",
    "                if i == 11: #height\n",
    "                    feature = feature/1000\n",
    "\n",
    "                normalized_feature.append(feature)\n",
    "            normalized_feature = np.array(normalized_feature).swapaxes(0,1).tolist()\n",
    "            normalized_data.append(normalized_feature)\n",
    "    \n",
    "\n",
    "    elif identifier == \"IMU\":\n",
    "        #acceleration average gets scaled by 9.81m/s^2\n",
    "        #gravity gets taken into account in y-direction\n",
    "        #everything else gets ignored, since the data is already in a sensible range\n",
    "        print(\"normalizing IMU data\")\n",
    "        for dataset in data:\n",
    "            normalized_feature = []\n",
    "            for i, feature in enumerate(np.array(dataset)):\n",
    "                if i == 0 or i ==2:\n",
    "                    feature = feature/9.81\n",
    "                if i == 1:\n",
    "                    feature = feature/9.81-1\n",
    "                normalized_feature.append(feature)\n",
    "            normalized_feature = np.array(normalized_feature).swapaxes(0,1)\n",
    "            print(normalized_feature.shape)\n",
    "            normalized_feature = normalized_feature.tolist()\n",
    "            normalized_data.append(normalized_feature)\n",
    "\n",
    "    elif identifier == \"gt\":\n",
    "        print(\"normalizing gt data\")\n",
    "        #latitude and longitude are scaled by 180°\n",
    "        #altitude is scaled by 12800m (flight level 420, the highest commercial flight level)\n",
    "        #speed is scaled by the speed of sound (343m/s)\n",
    "        #accuracy gets ignored\n",
    "        #bearing degrees are scaled by 360°\n",
    "        #utc time gets ignored\n",
    "        for dataset in data:\n",
    "            normalized_feature = []\n",
    "            for i, feature in enumerate(np.array(dataset)):\n",
    "                if i == 0 or i == 1:\n",
    "                    feature = feature#/180\n",
    "                normalized_feature.append(feature)\n",
    "            normalized_feature = np.array(normalized_feature).swapaxes(0,1).tolist()\n",
    "            normalized_data.append(normalized_feature)\n",
    "\n",
    "    \n",
    "    else:\n",
    "        print(\"normalizing arbitrary data\")\n",
    "        scaler = preprocess.MinMaxScaler()\n",
    "        for sample in data:\n",
    "            data_range = []\n",
    "            normalized_data.append(scaler.fit_transform(sample))\n",
    "        normalized_data=np.array(normalized_data)\n",
    "\n",
    "    \n",
    "\n",
    "    return normalized_data    \n",
    "    \n",
    "    \n",
    "\n",
    "def unnormalize(data, identifier):\n",
    "    '''unnormalize data\n",
    "    that was previously normalized with the normalize_data function\n",
    "\n",
    "    Args:\n",
    "    data to be unnormalized\n",
    "    type of data, to use standard predifenied normalization methods, since the type of data is knwon\n",
    "\n",
    "    Returns:\n",
    "    unnormalized data\n",
    "    '''\n",
    "\n",
    "    unnormalized_data = []\n",
    "    scaler = -1 #initialize undefined scaler\n",
    "\n",
    "    #differentiate which data comes is\n",
    "    if identifier == \"gnss\":\n",
    "        print(\"unnormalizing gnss data\")\n",
    "        #utc time gets ignored\n",
    "        #pseudorange is scaled (x-18*10^6m)/10^7m (satellites are at 20*10^6m orbital height. received signals dont go over 30*10^6m)\n",
    "        #pseudorange uncertainty is scaled by 25m (a typically high value)\n",
    "        #satellite postion is scaled by 20*10^6m which is a orbital heigth\n",
    "        for dataset in data:\n",
    "            unnormalized_feature = []\n",
    "            for i, feature in enumerate(np.array(dataset)):\n",
    "                if i == 1: #PseudorangeRate\n",
    "                    feature = feature*800\n",
    "                if i == 2: #raw pseudorange-lsrb\n",
    "                    feature = feature*10000000+18*10**6\n",
    "                if i == 3: #pseudorange uncertainty\n",
    "                    feature = feature*25\n",
    "                if i ==4: #ionospheric delay\n",
    "                    feature = feature*16\n",
    "                if i == 5: #tropospheric delay\n",
    "                    feature = feature*60\n",
    "                if i in [6,7]: #satellite position\n",
    "                    feature = feature*180\n",
    "                if i == 8: #satellite height\n",
    "                    feature = feature*(30*10**6)\n",
    "                if i in [9,10]: #wls position\n",
    "                    #feature = feature/6378137\n",
    "                    feature = feature#*180\n",
    "                if i == 11: #height\n",
    "                    feature = feature*1000\n",
    "                unnormalized_feature.append(feature)\n",
    "            unnormalized_feature = np.array(unnormalized_feature).tolist()\n",
    "            unnormalized_data.append(unnormalized_feature)\n",
    "\n",
    "    elif identifier == \"IMU\":\n",
    "        #acceleration average gets scaled by 9.81m/s^2\n",
    "        #gravity gets taken into account in y-direction\n",
    "        #everything else gets ignored, since the data is already in a sensible range\n",
    "        print(\"unnormalizing IMU data\")\n",
    "        for dataset in data:\n",
    "            unnormalized_feature = []\n",
    "            for i, feature in enumerate(np.array(dataset)):\n",
    "                if i == 0 or i ==2:\n",
    "                    feature = feature*9.81\n",
    "                if i == 1:\n",
    "                    feature = (feature+1)*9.81\n",
    "                unnormalized_feature.append(feature)\n",
    "            unnormalized_feature = np.array(unnormalized_feature).tolist()\n",
    "            unnormalized_data.append(unnormalized_feature)\n",
    "\n",
    "    elif identifier == \"gt\":\n",
    "        print(\"unnormalizing gt data\")\n",
    "        #latitude and longitude are scaled by 180°\n",
    "        #altitude is scaled by 12800m (flight level 420, the highest commercial flight level)\n",
    "        #speed is scaled by the speed of sound (343m/s)\n",
    "        #accuracy gets ignored\n",
    "        #bearing degrees are scaled by 360°\n",
    "        #utc time gets ignored\n",
    "        for dataset in data:\n",
    "            unnormalized_feature = []\n",
    "            for i, feature in enumerate(np.array(dataset)):\n",
    "                if i == 0 or i == 1: #latitude and longitude\n",
    "                    feature = feature#*180\n",
    "                # if i == 2: #altitude\n",
    "                #     feature = feature*12800\n",
    "                # if i == 3: #speed\n",
    "                #     feature = feature*343\n",
    "                # if i == 5: #bearing\n",
    "                #     feature = feature*360\n",
    "                unnormalized_feature.append(feature)\n",
    "            unnormalized_feature = np.array(unnormalized_feature).tolist()\n",
    "            unnormalized_data.append(unnormalized_feature)\n",
    "\n",
    "    else:\n",
    "        print(\"unnormalizing arbitrary data\")\n",
    "        scaler = preprocess.MinMaxScaler()\n",
    "        for sample in data:\n",
    "            data_range = []\n",
    "            unnormalized_data.append(scaler.inverse_transform(sample))\n",
    "        unnormalized_data=np.array(unnormalized_data)\n",
    "\n",
    "    return unnormalized_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIME_SERIES_SIZE = 50\n",
    "\n",
    "def sort_data(train_input_data, train_gt_data, MAX_TRAJECTORIES,number_of_features=None):\n",
    "    '''sort data so that all satellite measurements with the same timestamp are in one line\n",
    "    and add IMU data to the train data and pad the data to the same length\n",
    "\n",
    "    Args:\n",
    "    TIME_SERIES_SIZE: size of the time series\n",
    "    train_input_data: input data\n",
    "    train_gt_data: ground truth data\n",
    "    MAX_TRAJECTORIES: maximum number of trajectories to be used\n",
    "    number_of_features: number of features to be used, if None to take maximum number of features occuring in the data\n",
    "\n",
    "    Returns:\n",
    "    train_input_data_padded: padded and sorted input data\n",
    "    train_gt_data: ground truth data\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #move all features with the same timestamp to one line and move converted eccf to llo coordinates to the end of the line\n",
    "    precalculated_llo = []\n",
    "    for sample in range(len(train_input_data)):\n",
    "        matches = 0\n",
    "        print(f\"sample {sample+1} sorted\")\n",
    "        timesteps = 0\n",
    "        precalculated_llo.append([train_input_data[sample][0][-3:]])\n",
    "        train_input_data[sample][0].pop(-3)\n",
    "        train_input_data[sample][0].pop(-3)\n",
    "        train_input_data[sample][0].pop(-3)\n",
    "        for step in range(len(train_input_data[sample])):\n",
    "            if step != 0:\n",
    "                if train_input_data[sample][step-matches][0] == train_input_data[sample][step-1-matches][0]:\n",
    "                    train_input_data[sample][step-1-matches].extend(train_input_data[sample][step-matches][1:-3])\n",
    "                    train_input_data[sample].pop(step-matches)\n",
    "                    matches +=1\n",
    "                else:\n",
    "                    precalculated_llo[sample].append(train_input_data[sample][step-matches][-3:])\n",
    "                    train_input_data[sample][step-matches].pop(-3)\n",
    "                    train_input_data[sample][step-matches].pop(-3)\n",
    "                    train_input_data[sample][step-matches].pop(-3)\n",
    "                    timesteps+=1\n",
    "\n",
    "    #read in imu data and add it to the train data\n",
    "    print(\"reading imu data\")\n",
    "    IMU_data = read_imu_data(train_input_data, MAX_TRAJECTORIES)\n",
    "    IMU_data = normalize_data(IMU_data, \"IMU\")\n",
    "\n",
    "    #pad input data\n",
    "    print(\"padding train data\")\n",
    "    if number_of_features == None:\n",
    "        max_features = max([len(timestep) for sample in train_input_data for timestep in sample])\n",
    "    else:\n",
    "        max_features = number_of_features\n",
    "\n",
    "\n",
    "    train_input_data_padded = [tf.keras.preprocessing.sequence.pad_sequences(sample,value=0, padding=\"post\", dtype=np.float64, maxlen=max_features).tolist() for sample in train_input_data]\n",
    "    #train_input_data_padded = np.array(train_input_data_padded)\n",
    "\n",
    "    del train_input_data\n",
    "\n",
    "    #insert IMU data at the end of train data\n",
    "    print(\"inserting IMU data\")\n",
    "    for i, sample in enumerate(train_input_data_padded):\n",
    "        for j, timestep in enumerate(sample):\n",
    "            timestep.extend(IMU_data[i][j])\n",
    "    #train_input_data_padded = np.concatenate((train_input_data_padded, IMU_data_batched), axis=2)\n",
    "    del IMU_data\n",
    "\n",
    "    #insert llo data at the end of train data\n",
    "    print(\"inserting llo data\")\n",
    "    for i, sample in enumerate(train_input_data_padded):\n",
    "        for j, timestep in enumerate(sample):\n",
    "            timestep.extend([precalculated_llo[i][j][2], precalculated_llo[i][j][0], precalculated_llo[i][j][1]])\n",
    "    \n",
    "\n",
    "\n",
    "    #remove timestamp\n",
    "    for i in range(len(train_input_data_padded)):\n",
    "        for j in range(len(train_input_data_padded[i])):\n",
    "            train_input_data_padded[i][j].pop(0)\n",
    "    # for i in range(len(train_gt_data)):\n",
    "    #     for j in range(len(train_gt_data[i])):\n",
    "    #         train_gt_data[i][j].pop(6)\n",
    "    return train_input_data_padded, train_gt_data\n",
    "\n",
    "\n",
    "def batch_data(TIME_SERIES_SIZE, train_input_data_padded, train_gt_data, validation_split,batch_size):\n",
    "    '''prepare batches of time series of size TIME_SERIES_SIZE\n",
    "    and split data into training and validation data#\n",
    "\n",
    "    Args:\n",
    "    TIME_SERIES_SIZE: size of the time series\n",
    "    train_input_data: input data\n",
    "    train_gt_data: ground truth data\n",
    "    validation_split: percentage of data to be used for validation\n",
    "    batch_size: size of the batches\n",
    "\n",
    "    Returns:\n",
    "    train_data: tf dataset of prepared timeseries of the input data and ground truth data\n",
    "    validation_data: tf dataset of prepared timeseries of the input data and ground truth data\n",
    "    '''\n",
    "    #convert elements in train_input_data_padded and train_gt_data to np.float64\n",
    "    train_input_data_padded = [np.array(sample, dtype=np.float64) for sample in train_input_data_padded] \n",
    "    train_gt_data = [np.array(sample, dtype=np.float64) for sample in train_gt_data]\n",
    "    #preparte one tf dataset of prepared timeseries of the input data\n",
    "    train_input_data_batches = [tf.keras.utils.timeseries_dataset_from_array(train_sample, gt_sample[TIME_SERIES_SIZE:], TIME_SERIES_SIZE, sequence_stride=1, sampling_rate=1, batch_size=batch_size, shuffle=False) for train_sample, gt_sample in zip(train_input_data_padded, train_gt_data)]\n",
    "    #set datatype to float64\n",
    "    for trajectory in train_input_data_batches:\n",
    "        trajectory.output_types = np.float64\n",
    "\n",
    "\n",
    "    #split data into training and validation data\n",
    "    if validation_split == 0 or validation_split==None:\n",
    "        validation_data_batched = None\n",
    "\n",
    "        train_input_data_batched = train_input_data_batches[0]\n",
    "        for i in range(1,len(train_input_data_batches)):\n",
    "            train_input_data_batched = train_input_data_batched.concatenate(train_input_data_batches[i])\n",
    "\n",
    "        del train_input_data_padded, train_input_data_batches\n",
    "    else:\n",
    "        train_input_data_batches, validation_data_batches = train_test_split(train_input_data_batches, test_size=validation_split, train_size=1-validation_split)\n",
    "\n",
    "        train_input_data_batched = train_input_data_batches[0]\n",
    "        for i in range(1,len(train_input_data_batches)):\n",
    "            train_input_data_batched = train_input_data_batched.concatenate(train_input_data_batches[i])\n",
    "\n",
    "        validation_data_batched = validation_data_batches[0]\n",
    "        for i in range(1,len(validation_data_batches)):\n",
    "            validation_data_batched = validation_data_batched.concatenate(validation_data_batches[i])\n",
    "\n",
    "        del train_input_data_padded, train_input_data_batches, train_gt_data, validation_data_batches\n",
    "\n",
    "    return train_input_data_batched, validation_data_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(lat1, lon1, lat2, lon2):  # generally used geo measurement function\n",
    "    R = 6378.137; # Radius of earth in KM\n",
    "    dLat = lat2 * np.pi / 180 - lat1 * np.pi / 180\n",
    "    dLon = lon2 * np.pi / 180 - lon1 * np.pi / 180\n",
    "    a = np.sin(dLat/2) * np.sin(dLat/2) + np.cos(lat1 * np.pi / 180) * np.cos(lat2 * np.pi / 180) *  np.sin(dLon/2) * np.sin(dLon/2)\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = R * c\n",
    "    return d * 10000; #decimeters\n",
    "\n",
    "\n",
    "class DecimeterError(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(DecimeterError, self).__init__()\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "    \n",
    "    def on_training_begin(self, logs=None):\n",
    "        super().on_training_begin(logs)\n",
    "    \n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        super().on_batch_begin(batch, logs)\n",
    "\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        super().on_batch_end(batch, logs)\n",
    "\n",
    "\n",
    "    def on_training_end(self, epoch, logs=None):\n",
    "        super().on_training_end(epoch, logs)\n",
    "        ly_pred = self.model.predict(train_input_data_padded_normalized)\n",
    "        ly_true = train_gt_data_padded_normalized\n",
    "        ly_pred = np.array([gt_scaler.inverse_transform(sample) for sample in ly_pred])\n",
    "        ly_true = np.array([gt_scaler.inverse_transform(sample) for sample in ly_true])\n",
    "        error = measure(ly_pred[:,:,0], ly_pred[:,:,1], ly_true[:,:,0], ly_true[:,:,1])\n",
    "        total_avg_error = np.mean(error)\n",
    "        print(f\"decimeter error: {total_avg_error}\")\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], input_shape[-1]), initializer=\"random_normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[-1],), initializer=\"zeros\")\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        score = tf.nn.tanh(tf.tensordot(inputs, self.W, axes=1) + self.b)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * inputs\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing gt data\n",
      "normalizing gnss data\n",
      "sample 1 sorted\n",
      "sample 2 sorted\n",
      "sample 3 sorted\n",
      "sample 4 sorted\n",
      "sample 5 sorted\n",
      "sample 6 sorted\n",
      "sample 7 sorted\n",
      "sample 8 sorted\n",
      "sample 9 sorted\n",
      "sample 10 sorted\n",
      "sample 11 sorted\n",
      "sample 12 sorted\n",
      "sample 13 sorted\n",
      "sample 14 sorted\n",
      "sample 15 sorted\n",
      "sample 16 sorted\n",
      "sample 17 sorted\n",
      "sample 18 sorted\n",
      "sample 19 sorted\n",
      "sample 20 sorted\n",
      "reading imu data\n",
      "read in 1 samples\n",
      "read in 2 samples\n",
      "read in 3 samples\n",
      "read in 4 samples\n",
      "read in 5 samples\n",
      "read in 6 samples\n",
      "read in 7 samples\n",
      "read in 8 samples\n",
      "read in 9 samples\n",
      "read in 10 samples\n",
      "read in 11 samples\n",
      "read in 12 samples\n",
      "read in 13 samples\n",
      "read in 14 samples\n",
      "read in 15 samples\n",
      "read in 16 samples\n",
      "read in 17 samples\n",
      "read in 18 samples\n",
      "read in 19 samples\n",
      "read in 20 samples\n",
      "normalizing IMU data\n",
      "(1300, 12)\n",
      "(1303, 12)\n",
      "(2131, 12)\n",
      "(2147, 12)\n",
      "(1929, 12)\n",
      "(1699, 12)\n",
      "(1700, 12)\n",
      "(1691, 12)\n",
      "(1629, 12)\n",
      "(1628, 12)\n",
      "(1881, 12)\n",
      "(1870, 12)\n",
      "(1830, 12)\n",
      "(1495, 12)\n",
      "(1408, 12)\n",
      "(1408, 12)\n",
      "(1408, 12)\n",
      "(1408, 12)\n",
      "(2002, 12)\n",
      "(2004, 12)\n",
      "padding train data\n",
      "inserting IMU data\n",
      "inserting llo data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EPOCHS = 12\n",
    "BATCH_SIZE = 32\n",
    "SAMPLES = 20\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "clear_session()\n",
    "\n",
    "#load data outside of optimize function and only do batching and training inside of it\n",
    "train_input_data, train_gt_data = read_data(SAMPLES)\n",
    "train_gt_data_normalized = normalize_data(train_gt_data, \"gt\")\n",
    "train_input_data_normalized = normalize_data(train_input_data, \"gnss\")\n",
    "train_input_data_padded, train_gt_data_padded = sort_data(train_input_data_normalized, train_gt_data_normalized, SAMPLES)\n",
    "del train_input_data, train_gt_data, train_input_data_normalized, train_gt_data_normalized\n",
    "\n",
    "def objective(trial):\n",
    "    global train_input_data_padded, train_gt_data_padded, scaler\n",
    "    TIME_SERIES_SIZE = trial.suggest_int(\"TIME_SERIES_SIZE\", 3, 50)\n",
    "    \n",
    "    train_data, validation_data = batch_data(TIME_SERIES_SIZE, train_input_data_padded, train_gt_data_padded, VALIDATION_SPLIT, BATCH_SIZE)\n",
    "    print(\"creating model\")\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"tanh\", \"sigmoid\", \"softmax\", \"elu\"])\n",
    "    filter_activation = trial.suggest_categorical(\"filter_activation\", [\"tanh\", \"sigmoid\", \"softmax\", \"elu\", \"relu\"])\n",
    "\n",
    "    input = Input(shape=(iter(train_data).next()[0].shape[1], iter(train_data).next()[0].shape[2]))\n",
    "    input_split = [input[:, :, :-2], input[:, :, -2:]]\n",
    "    feature_masking = Masking(mask_value=0)(input_split[0])\n",
    "    feature_processing = Dense(iter(train_data).next()[0].shape[2] - 2, activation=filter_activation)(feature_masking)\n",
    "    \n",
    "    for i in range(n_layers - 1):\n",
    "        feature_processing = LSTM(trial.suggest_int(f\"n_units_l{i}\", 2, 500), activation=activation, return_sequences=True)(feature_processing)\n",
    "    \n",
    "\n",
    "    \n",
    "    feature_processing = LSTM(trial.suggest_int(f\"n_units_l{n_layers - 1}\", 2, 500), activation=activation)(attention_output)\n",
    "    error_prediction = Dense(iter(train_data).next()[1].shape[1], activation=\"linear\")(feature_processing)\n",
    "    flatten_llo = input_split[1][:, -1, :]\n",
    "    output = Add()([error_prediction, flatten_llo])\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate), loss=\"MeanSquaredError\")\n",
    "\n",
    "    print(f\"training model with {TIME_SERIES_SIZE} timesteps, {n_layers} layers, {activation} activation, {learning_rate} learning rate\")\n",
    "    history = model.fit(train_data, epochs=EPOCHS, validation_data=validation_data, callbacks=[PlotLossesKeras(), DecimeterError()], verbose=1)\n",
    "    \n",
    "    # Return validation score as indicator for the model quality\n",
    "    try:\n",
    "        returnvalue = history.history[\"val_loss\"][-1]\n",
    "    except KeyError:\n",
    "        print(history.history.keys())\n",
    "        returnvalue = history.history[\"loss\"][-1]\n",
    "    return returnvalue\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"final results\"\n",
    "study_name = \"kaggle optimization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    0.000, max:    0.014, cur:    0.000)\n",
      "\tvalidation       \t (min:   27.173, max:   27.211, cur:   27.176)\n",
      "\u001b[1m831/831\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 177ms/step - loss: 1.3592e-04 - val_loss: 27.1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-06 08:48:45,848] Trial 19 finished with value: 27.17634391784668 and parameters: {'TIME_SERIES_SIZE': 44, 'n_layers': 1, 'activation': 'elu', 'filter_activation': 'tanh', 'n_units_l0': 275, 'learning_rate': 1.0437090930113108e-05}. Best is trial 2 with value: 6.591469059458177e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model\n",
      "training model with 35 timesteps, 3 layers, tanh activation, 3.873415012541019e-05 learning rate\n",
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-08-06 08:48:54,742] Trial 20 failed with parameters: {'TIME_SERIES_SIZE': 35, 'n_layers': 3, 'activation': 'tanh', 'filter_activation': 'elu', 'n_units_l0': 356, 'n_units_l1': 241, 'n_units_l2': 226, 'learning_rate': 3.873415012541019e-05} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1563, in get_attr\n",
      "    pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Operation 'adam/AssignSubVariableOp_16' has no attr named '_read_only_resource_inputs'.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps_utils.py\", line 105, in get_read_write_resource_inputs\n",
      "    read_only_input_indices = op.get_attr(READ_ONLY_RESOURCE_INPUTS_ATTR)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1567, in get_attr\n",
      "    raise ValueError(e.message)\n",
      "ValueError: Operation 'adam/AssignSubVariableOp_16' has no attr named '_read_only_resource_inputs'.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\klink\\AppData\\Local\\Temp\\ipykernel_7400\\3906577661.py\", line 50, in objective\n",
      "    history = model.fit(train_data, epochs=EPOCHS, validation_data=validation_data, callbacks=[PlotLossesKeras(), DecimeterError()], verbose=1)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 318, in fit\n",
      "    logs = self.train_function(iterator)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 833, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 889, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 696, in _initialize\n",
      "    self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\", line 178, in trace_function\n",
      "    concrete_function = _maybe_define_function(\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\", line 283, in _maybe_define_function\n",
      "    concrete_function = _create_concrete_function(\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\", line 310, in _create_concrete_function\n",
      "    traced_func_graph = func_graph_module.func_graph_from_py_func(\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1059, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 599, in wrapped_fn\n",
      "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py\", line 41, in autograph_handler\n",
      "    return api.converted_call(\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 339, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 459, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 121, in one_step_on_iterator\n",
      "    outputs = self.distribute_strategy.run(\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 1673, in run\n",
      "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 3263, in call_for_each_replica\n",
      "    return self._call_for_each_replica(fn, args, kwargs)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 4061, in _call_for_each_replica\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 833, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 906, in _call\n",
      "    return tracing_compilation.call_function(\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\", line 132, in call_function\n",
      "    function = trace_function(\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\", line 178, in trace_function\n",
      "    concrete_function = _maybe_define_function(\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\", line 283, in _maybe_define_function\n",
      "    concrete_function = _create_concrete_function(\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\", line 310, in _create_concrete_function\n",
      "    traced_func_graph = func_graph_module.func_graph_from_py_func(\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 987, in func_graph_from_py_func\n",
      "    with func_graph.as_default(), deps_control_manager as deps_ctx:\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py\", line 459, in __exit__\n",
      "    for inp, resource_type in _get_resource_inputs(op):\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py\", line 608, in _get_resource_inputs\n",
      "    reads, writes = utils.get_read_write_resource_inputs(op)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps_utils.py\", line 108, in get_read_write_resource_inputs\n",
      "    writes.update(t for t in op.inputs if t.dtype == dtypes.resource)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1467, in inputs\n",
      "    self._inputs_val = tuple(\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1468, in <genexpr>\n",
      "    self.graph._get_tensor_by_tf_output(i)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3053, in _get_tensor_by_tf_output\n",
      "    op = self._get_operation_by_tf_operation(tf_output.oper)\n",
      "  File \"c:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3012, in _get_operation_by_tf_operation\n",
      "    op_name = pywrap_tf_session.TF_OperationName(tf_oper)\n",
      "KeyboardInterrupt\n",
      "[W 2024-08-06 08:48:54,805] Trial 20 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1563\u001b[0m, in \u001b[0;36mOperation.get_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m c_api_util\u001b[38;5;241m.\u001b[39mtf_buffer() \u001b[38;5;28;01mas\u001b[39;00m buf:   \u001b[38;5;66;03m# pytype: disable=wrong-arg-count\u001b[39;00m\n\u001b[1;32m-> 1563\u001b[0m   \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_OperationGetAttrValueProto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m   data \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(buf)\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Operation 'adam/AssignSubVariableOp_16' has no attr named '_read_only_resource_inputs'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps_utils.py:105\u001b[0m, in \u001b[0;36mget_read_write_resource_inputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m   read_only_input_indices \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREAD_ONLY_RESOURCE_INPUTS_ATTR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;66;03m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1567\u001b[0m, in \u001b[0;36mOperation.get_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1566\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 1567\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m   1568\u001b[0m x \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "\u001b[1;31mValueError\u001b[0m: Operation 'adam/AssignSubVariableOp_16' has no attr named '_read_only_resource_inputs'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m,study_name\u001b[38;5;241m=\u001b[39mstudy_name, storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.db\u001b[39m\u001b[38;5;124m\"\u001b[39m, load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[38], line 50\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     47\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeanSquaredError\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining model with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTIME_SERIES_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timesteps, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layers, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactivation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m activation, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearning_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m learning rate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mPlotLossesKeras\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDecimeterError\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Return validation score as indicator for the model quality\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:889\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    887\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    888\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 889\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    892\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    893\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[0;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[0;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[0;32m    694\u001b[0m )\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    290\u001b[0m   )\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[0;32m    304\u001b[0m       placeholder_context\n\u001b[0;32m    305\u001b[0m   )\n\u001b[0;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    309\u001b[0m )\n\u001b[1;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[0;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:339\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[0;32m    338\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph artifact\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[1;32m--> 339\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools\u001b[38;5;241m.\u001b[39mpartial):\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:121\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m--> 121\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_step_on_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    125\u001b[0m     outputs,\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m    127\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    128\u001b[0m )\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1673\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1669\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1670\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1671\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1672\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3263\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3261\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   3262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 3263\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4061\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   4059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   4060\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 4061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:906\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[1;32m--> 906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    910\u001b[0m   bound_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\n\u001b[0;32m    911\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds\n\u001b[0;32m    912\u001b[0m   )\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[0;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[0;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[0;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    290\u001b[0m   )\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[0;32m    304\u001b[0m       placeholder_context\n\u001b[0;32m    305\u001b[0m   )\n\u001b[0;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    309\u001b[0m )\n\u001b[1;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[0;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:987\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    985\u001b[0m   deps_control_manager \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mNullContextmanager()\n\u001b[1;32m--> 987\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m func_graph\u001b[38;5;241m.\u001b[39mas_default(), deps_control_manager \u001b[38;5;28;01mas\u001b[39;00m deps_ctx:\n\u001b[0;32m    988\u001b[0m   current_scope \u001b[38;5;241m=\u001b[39m variable_scope\u001b[38;5;241m.\u001b[39mget_variable_scope()\n\u001b[0;32m    989\u001b[0m   default_use_resource \u001b[38;5;241m=\u001b[39m current_scope\u001b[38;5;241m.\u001b[39muse_resource\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py:459\u001b[0m, in \u001b[0;36mAutomaticControlDependencies.__exit__\u001b[1;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[0;32m    456\u001b[0m resource_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;66;03m# Check for any resource inputs. If we find any, we update control_inputs\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;66;03m# and last_write_to_resource.\u001b[39;00m\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inp, resource_type \u001b[38;5;129;01min\u001b[39;00m _get_resource_inputs(op):\n\u001b[0;32m    460\u001b[0m   is_read \u001b[38;5;241m=\u001b[39m resource_type \u001b[38;5;241m==\u001b[39m ResourceType\u001b[38;5;241m.\u001b[39mREAD_ONLY\n\u001b[0;32m    461\u001b[0m   input_id \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mtensor_id(inp)\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py:608\u001b[0m, in \u001b[0;36m_get_resource_inputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_resource_inputs\u001b[39m(op):\n\u001b[0;32m    607\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m   reads, writes \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_read_write_resource_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    609\u001b[0m   saturated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    610\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m saturated:\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps_utils.py:108\u001b[0m, in \u001b[0;36mget_read_write_resource_inputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    105\u001b[0m   read_only_input_indices \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mget_attr(READ_ONLY_RESOURCE_INPUTS_ATTR)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;66;03m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m   writes\u001b[38;5;241m.\u001b[39mupdate(t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mresource)\n\u001b[0;32m    109\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (reads, writes)\n\u001b[0;32m    111\u001b[0m read_only_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1467\u001b[0m, in \u001b[0;36mOperation.inputs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The sequence of `Tensor` objects representing the data inputs of this op.\"\"\"\u001b[39;00m\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1466\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1467\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1468\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tensor_by_tf_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1469\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGetOperationInputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c_op\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1470\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs_val\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1468\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The sequence of `Tensor` objects representing the data inputs of this op.\"\"\"\u001b[39;00m\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1466\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m-> 1468\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tensor_by_tf_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1469\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m pywrap_tf_session\u001b[38;5;241m.\u001b[39mGetOperationInputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_op))\n\u001b[0;32m   1470\u001b[0m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs_val\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3053\u001b[0m, in \u001b[0;36mGraph._get_tensor_by_tf_output\u001b[1;34m(self, tf_output)\u001b[0m\n\u001b[0;32m   3040\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_tensor_by_tf_output\u001b[39m(\u001b[38;5;28mself\u001b[39m, tf_output) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tensor_lib\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m   3041\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the `Tensor` representing `tf_output`.\u001b[39;00m\n\u001b[0;32m   3042\u001b[0m \n\u001b[0;32m   3043\u001b[0m \u001b[38;5;124;03m  Note that there is only one such `Tensor`, i.e. multiple calls to this\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3051\u001b[0m \u001b[38;5;124;03m    The `Tensor` that represents `tf_output`.\u001b[39;00m\n\u001b[0;32m   3052\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3053\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_operation_by_tf_operation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3054\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39moutputs[tf_output\u001b[38;5;241m.\u001b[39mindex]\n",
      "File \u001b[1;32mc:\\google_decimeter_challenge\\GoogleDecimeterChallenge\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3012\u001b[0m, in \u001b[0;36mGraph._get_operation_by_tf_operation\u001b[1;34m(self, tf_oper)\u001b[0m\n\u001b[0;32m   3011\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_operation_by_tf_operation\u001b[39m(\u001b[38;5;28mself\u001b[39m, tf_oper) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 3012\u001b[0m   op_name \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_OperationName\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_oper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3013\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_operation_by_name(op_name)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(save_path, exist_ok=True)\n",
    "study = optuna.create_study(direction=\"minimize\",study_name=study_name, storage=f\"sqlite:///{save_path}/{study_name}.db\", load_if_exists=True)\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TIME_SERIES_SIZE': 39, 'n_layers': 3, 'activation': 'softmax', 'filter_activation': 'relu', 'n_units_l0': 155, 'n_units_l1': 248, 'n_units_l2': 400, 'learning_rate': 1.715720851066559e-05}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "study.trials_dataframe().to_csv(f\"{save_path}/{study_name}.csv\")\n",
    "print(study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TIME_SERIES_SIZE': 20, 'n_lstm_layers': 6, 'n_preprocessing_layers': 10, 'activation': 'softmax', 'filter_activation': 'sigmoid', 'n_units_preprocess_l0': 354, 'n_units_preprocess_l1': 88, 'n_units_preprocess_l2': 21, 'n_units_preprocess_l3': 258, 'n_units_preprocess_l4': 205, 'n_units_preprocess_l5': 476, 'n_units_preprocess_l6': 187, 'n_units_preprocess_l7': 29, 'n_units_preprocess_l8': 231, 'n_units_preprocess_l9': 37, 'n_units_l0': 170, 'n_units_l1': 467, 'n_units_l2': 332, 'n_units_l3': 385, 'n_units_l4': 166, 'n_units_l5': 174, 'learning_rate': 0.0006758987765022343}\n"
     ]
    }
   ],
   "source": [
    "loaded_study = optuna.load_study(study_name=study_name, storage=f\"sqlite:///{save_path}/{study_name}.db\")\n",
    "print(loaded_study.best_params)\n",
    "fig = optuna.visualization.plot_parallel_coordinate(loaded_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default float precision: float64\n",
      "Updated float precision: float64\n"
     ]
    }
   ],
   "source": [
    "#train model with best params\n",
    "SAMPLES = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "#params = loaded_study.best_params\n",
    "#params = loaded_study.trials[41].params\n",
    "#params = {'TIME_SERIES_SIZE': 10, 'n_layers': 2, 'activation': 'tanh', 'n_units_l0': 200, 'n_units_l1': 80, 'n_units_l2': 100, 'n_units_l3': 100, 'n_units_l4': 80, 'n_units_l5': 80, 'n_units_l6': 80, 'n_units_l7': 60, 'n_units_l8': 50, 'n_units_l9': 30, 'learning_rate': 0.1e-5}\n",
    "params = {'TIME_SERIES_SIZE': 40, 'n_layers': 2, 'activation': 'tanh', 'filter_activation': 'elu', 'n_units_l0': 300, 'n_units_l1': 50, \"n_units_l2\": 200, \"n_units_l3\": 200,\"n_units_l4\": 50,\"n_units_l5\": 20,'learning_rate': 0.1e-3}\n",
    "\n",
    "#set tf precision to float 64\n",
    "#Check default float precision\n",
    "print(\"Default float precision:\", tf.keras.backend.floatx())\n",
    "\n",
    "#Change default float precision to float64\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "print(\"Updated float precision:\", tf.keras.backend.floatx())\n",
    "#reset the keras session\n",
    "clear_session()\n",
    "\n",
    "TIME_SERIES_SIZE = params[\"TIME_SERIES_SIZE\"]\n",
    "train_input_data, train_gt_data = read_data(SAMPLES)\n",
    "train_gt_data_normalized = normalize_data(train_gt_data, \"gt\")\n",
    "train_input_data_normalized = normalize_data(train_input_data, \"gnss\")\n",
    "train_input_data_padded, train_gt_data_padded = sort_data(train_input_data_normalized, train_gt_data_normalized, SAMPLES)\n",
    "train_data, validation_data = batch_data(TIME_SERIES_SIZE, train_input_data_padded, train_gt_data_padded, VALIDATION_SPLIT, BATCH_SIZE)\n",
    "del train_input_data, train_gt_data, train_input_data_normalized, train_gt_data_normalized, train_input_data_padded, train_gt_data_padded\n",
    "    \n",
    "\n",
    "n_layers = params[\"n_lstm_layers\"]\n",
    "activation = params[\"activation\"]\n",
    "\n",
    "\n",
    "n_layers = params[\"n_layers\"]\n",
    "activation = params[\"activation\"]\n",
    "\n",
    "#input and split off llo data to be added to the nwtrwork output\n",
    "input = Input(shape=(iter(train_data).next()[0].shape[1], iter(train_data).next()[0].shape[2]))\n",
    "input_split = [input[:,:,:-2], input[:,:,-2:]]\n",
    "feature_masking = Masking(mask_value=0)(input_split[0])\n",
    "feature_processing = Dense(iter(train_data).next()[0].shape[2] - 2, activation=params[\"filter_activation\"])(feature_masking)\n",
    "\n",
    "#feature_processing = Dense(iter(train_data).next()[0].shape[2]-2, activation=\"linear\")(feature_masking)\n",
    "\n",
    "for i in range(params[\"n_preprocessing_layers\"]):\n",
    "        feature_processing = Dense(params[f\"n_units_preprocess_l{i}\"], activation=params[\"filter_activation\"])(feature_processing)\n",
    "\n",
    "for i in range(n_layers-1):\n",
    "    feature_processing = LSTM(params[f\"n_units_l{i}\"], activation=activation, return_sequences=True)(feature_processing)\n",
    "# Add Multi-Head Attention Layer\n",
    "multi_head_attention = MultiHeadAttention(num_heads=8, key_dim=64)(feature_processing, feature_processing)\n",
    "attention_output = LayerNormalization(epsilon=1e-6)(multi_head_attention)\n",
    "attention_output = Dropout(0.1)(attention_output)\n",
    "feature_processing = LSTM(params[f\"n_units_l{n_layers-1}\"], activation=activation)(feature_processing)\n",
    "\n",
    "\n",
    "# feature_processing = Dense(100, activation=\"sigmoid\")(feature_processing)\n",
    "# feature_processing = Dense(50, activation=\"sigmoid\")(feature_processing)\n",
    "# feature_processing = Dense(25, activation=\"sigmoid\")(feature_processing)\n",
    "# feature_processing = Dense(10, activation=\"sigmoid\")(feature_processing)\n",
    "\n",
    "\n",
    "error_prediction = Dense(iter(train_data).next()[1].shape[1], activation=\"linear\")(feature_processing)\n",
    "flatten_llo = input_split[1][:,-1,:]\n",
    "output = Add()([error_prediction, flatten_llo])\n",
    "\n",
    "model = tf.keras.Model(inputs=input, outputs=output)\n",
    "\n",
    "learning_rate = params[\"learning_rate\"]\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate), loss=\"MeanSquaredError\")\n",
    "#model.compile(optimizer=\"Adam\", loss=\"MeanSquaredError\")\n",
    "print(model.summary())\n",
    "\n",
    "first = iter(train_data).next()\n",
    "first_input = first[0][0]\n",
    "first_gt = first[1]\n",
    "print(first_gt[0][0].dtype)\n",
    "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
    "\n",
    "history = model.fit(train_data, epochs=EPOCHS, validation_data=validation_data, callbacks=[PlotLossesKeras(), DecimeterError()], verbose=1)\n",
    "#return validation score as indicator for the model quality\n",
    "#print(history.history[\"val_loss\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data, epochs=200, validation_data=validation_data, callbacks=[PlotLossesKeras(), DecimeterError()], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in 1 samples\n",
      "normalizing gt data\n",
      "normalizing gnss data\n",
      "(None, 10, 351)\n",
      "sample 1 sorted\n",
      "reading imu data\n",
      "read in 1 samples\n",
      "normalizing IMU data\n",
      "(1300, 12)\n",
      "padding train data\n",
      "inserting IMU data\n",
      "inserting llo data\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "unnormalizing gt data\n",
      "unnormalizing gt data\n",
      "datatype gt: float64\n",
      "unnormalizing gt data\n"
     ]
    }
   ],
   "source": [
    "# visualize trajectory on map\n",
    "trajectory_index = 0\n",
    "\n",
    "inp, outp = read_data(trajectory_index+1)\n",
    "path_data = [[inp[trajectory_index]], [outp[trajectory_index]]]\n",
    "\n",
    "\n",
    "gt_data_normalized = normalize_data(path_data[1], \"gt\")\n",
    "gnss_data_normalized = normalize_data(path_data[0], \"gnss\")\n",
    "print(model.input_shape)\n",
    "\n",
    "#input_data,_  = sort_data(TIME_SERIES_SIZE, gnss_data_normalized, gt_data_normalized, 1,None,BATCH_SIZE, model.input_shape[2]-11)\n",
    "gnss_data_padded, gt_data_padded = sort_data(gnss_data_normalized, gt_data_normalized, 1, model.input_shape[2]-14)\n",
    "input_data,_ = batch_data(TIME_SERIES_SIZE, np.array(gnss_data_padded)[:,:,:], gt_data_padded, 0, BATCH_SIZE)\n",
    "\n",
    "              \n",
    "prediction = model.predict(input_data)[:,:]\n",
    "prediction = np.array(unnormalize(prediction, \"gt\"))\n",
    "gt = np.array([unnormalize(sample, \"gt\") for sample in gt_data_normalized])\n",
    "print(f\"datatype gt: {gt.dtype}\")\n",
    "\n",
    "predicted_path = prediction[:,0:3]\n",
    "gt_path = gt[0,:,0:3]\n",
    "precalculated_data = unnormalize(np.array(gnss_data_padded)[0][:,-2:],\"gt\")\n",
    "\n",
    "\n",
    "#plot it on a map\n",
    "m = folium.Map(location=[predicted_path[0,0], predicted_path[0,1]], zoom_start=25, max_zoom=35)\n",
    "\n",
    "for i in range(len(predicted_path)-1):\n",
    "    folium.PolyLine([[predicted_path[i,0], predicted_path[i,1]], [predicted_path[i+1,0], predicted_path[i+1,1]]], color=\"blue\").add_to(m)\n",
    "    folium.PolyLine([[gt_path[i,0], gt_path[i,1]], [gt_path[i+1,0], gt_path[i+1,1]]], color=\"red\").add_to(m)\n",
    "\n",
    "for i in range(len(precalculated_data)-1):\n",
    "    folium.PolyLine([[precalculated_data[i][0], precalculated_data[i][1]], [precalculated_data[i+1][0], precalculated_data[i+1][1]]], color=\"green\").add_to(m)\n",
    "\n",
    "folium.Marker([predicted_path[-1,0], predicted_path[-1,1]], popup=f\"predicted: {predicted_path[-1,0]}, {predicted_path[-1,1]}\", icon=folium.Icon(color=\"red\")).add_to(m)\n",
    "folium.Marker([gt_path[-1,0], gt_path[-1,1]], popup=f\"gt: {gt_path[-1,0]}, {gt_path[-1,1]}\", icon=folium.Icon(color=\"red\")).add_to(m)\n",
    "\n",
    "m.save(\"map.html\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())\n",
    "weights = model.get_weights()\n",
    "#print(weights)\n",
    "print(weights[4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save(\"lstm only long run.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
