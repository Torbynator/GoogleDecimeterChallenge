{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for the GoogleDecimeterChallenge https://www.kaggle.com/competitions/smartphone-decimeter-2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also try to run it on google collab, works great only RAM is limited:\n",
    "https://colab.research.google.com/github/Torbynator/GoogleDecimeterChallenge/blob/main/main.ipynb#scrollTo=TOn-Can4C0YP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Only for google collab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install  kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
    "!kaggle competitions download -c smartphone-decimeter-2023\n",
    "!unzip /content/smartphone-decimeter-2023.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import math\n",
    "import os\n",
    "\n",
    "INPUT_PATH = 'sdc2023/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_input_data = []\n",
    "test_gt_data = []\n",
    "\n",
    "#iterate over all data files and store them in the respective arrays\n",
    "\n",
    "#load test data\n",
    "test_files = os.listdir(INPUT_PATH + \"test\")\n",
    "\n",
    "for folder in test_files:\n",
    "    smartphones = os.listdir(INPUT_PATH + \"test/\"+folder)\n",
    "    for smartphone in smartphones:\n",
    "        file =  \"/device_gnss.csv\"\n",
    "        #store data in list while dropping first and 41st column (string data)\n",
    "        test_input_data.append(pd.read_csv(INPUT_PATH + \"test/\" +folder+\"/\"+smartphone + file, usecols=[i for i in range(58) if i not in [0,40]], dtype=np.float32).to_numpy(dtype=np.float32).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in 1 samples\n",
      "read in 2 samples\n",
      "read in 3 samples\n",
      "read in 4 samples\n",
      "read in 5 samples\n",
      "read in 6 samples\n",
      "read in 7 samples\n",
      "read in 8 samples\n",
      "read in 9 samples\n",
      "read in 10 samples\n",
      "read in 11 samples\n",
      "read in 12 samples\n",
      "read in 13 samples\n",
      "read in 14 samples\n",
      "read in 15 samples\n",
      "read in 16 samples\n",
      "read in 17 samples\n",
      "read in 18 samples\n",
      "read in 19 samples\n",
      "read in 20 samples\n",
      "read in 21 samples\n",
      "read in 22 samples\n",
      "read in 23 samples\n",
      "read in 24 samples\n",
      "read in 25 samples\n",
      "read in 26 samples\n",
      "read in 27 samples\n",
      "read in 28 samples\n",
      "read in 29 samples\n",
      "read in 30 samples\n",
      "read in 31 samples\n",
      "read in 32 samples\n",
      "read in 33 samples\n",
      "read in 34 samples\n",
      "read in 35 samples\n",
      "read in 36 samples\n",
      "read in 37 samples\n",
      "read in 38 samples\n",
      "read in 39 samples\n",
      "read in 40 samples\n",
      "read in 41 samples\n",
      "read in 42 samples\n",
      "read in 43 samples\n",
      "read in 44 samples\n",
      "read in 45 samples\n",
      "read in 46 samples\n",
      "read in 47 samples\n",
      "read in 48 samples\n",
      "read in 49 samples\n",
      "read in 50 samples\n",
      "read in 51 samples\n",
      "read in 52 samples\n",
      "read in 53 samples\n",
      "read in 54 samples\n",
      "read in 55 samples\n",
      "read in 56 samples\n",
      "read in 57 samples\n",
      "read in 58 samples\n",
      "read in 59 samples\n",
      "read in 60 samples\n",
      "read in 61 samples\n",
      "read in 62 samples\n",
      "read in 63 samples\n",
      "read in 64 samples\n",
      "read in 65 samples\n",
      "read in 66 samples\n",
      "read in 67 samples\n",
      "read in 68 samples\n",
      "read in 69 samples\n",
      "read in 70 samples\n",
      "read in 71 samples\n",
      "read in 72 samples\n",
      "read in 73 samples\n",
      "read in 74 samples\n",
      "read in 75 samples\n",
      "read in 76 samples\n",
      "read in 77 samples\n",
      "read in 78 samples\n",
      "read in 79 samples\n",
      "read in 80 samples\n"
     ]
    }
   ],
   "source": [
    "#load train data\n",
    "MAX_SAMPLES = 80\n",
    "train_files = os.listdir(INPUT_PATH + \"train\")\n",
    "sample_count=0\n",
    "\n",
    "train_input_data = []\n",
    "train_gt_data = []\n",
    "\n",
    "for folder in train_files:\n",
    "    smartphones = os.listdir(INPUT_PATH + \"train/\"+folder)\n",
    "    for smartphone in smartphones:\n",
    "        files = os.listdir(INPUT_PATH + \"train/\"+folder+\"/\"+smartphone)\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                if sample_count >= MAX_SAMPLES:\n",
    "                    break   \n",
    "                if \"gnss\" in file:\n",
    "                    #store data in list while dropping first and 41st column (string data), as well as (porbably mostly) empty columns\n",
    "                    #also all data points with the same timestep are seen as features of one timestep of a sample\n",
    "                    train_input_data.append(pd.read_csv(INPUT_PATH + \"train/\" +folder+\"/\"+ smartphone+ \"/\" + file, usecols=[i for i in range(58) if i not in [0,2,3,4,23,24,25,27,28,19,29,30,31,32,33,34,35,36,40]], dtype=float).to_numpy(dtype=float).tolist())\n",
    "                elif \"ground_truth\" in file:\n",
    "                    sample_count +=1\n",
    "                    #store data in list while dropping first and 2nd column (string data),(porbably mostly) empty columns\n",
    "                    train_gt_data.append(pd.read_csv(INPUT_PATH + \"train/\"+folder+\"/\" + smartphone+ \"/\" + file,  usecols=[i for i in range(9) if i not in [0,1]], dtype=float).to_numpy(dtype=float).tolist())\n",
    "                    print(f\"read in {sample_count} samples\")\n",
    "\n",
    "\n",
    "#replace NaN values with 0\n",
    "train_input_data = [[[0 if math.isnan(x) else x for x in timestep] for timestep in sample ] for sample in train_input_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0\n",
      "sample 1\n",
      "sample 2\n",
      "sample 3\n",
      "sample 4\n",
      "sample 5\n",
      "sample 6\n",
      "sample 7\n",
      "sample 8\n",
      "sample 9\n",
      "sample 10\n",
      "sample 11\n",
      "sample 12\n",
      "sample 13\n",
      "sample 14\n",
      "sample 15\n",
      "sample 16\n",
      "sample 17\n",
      "sample 18\n",
      "sample 19\n",
      "sample 20\n",
      "sample 21\n",
      "sample 22\n",
      "sample 23\n",
      "sample 24\n",
      "sample 25\n",
      "sample 26\n",
      "sample 27\n",
      "sample 28\n",
      "sample 29\n",
      "sample 30\n",
      "sample 31\n",
      "sample 32\n",
      "sample 33\n",
      "sample 34\n",
      "sample 35\n",
      "sample 36\n",
      "sample 37\n",
      "sample 38\n",
      "sample 39\n",
      "sample 40\n",
      "sample 41\n",
      "sample 42\n",
      "sample 43\n",
      "sample 44\n",
      "sample 45\n",
      "sample 46\n",
      "sample 47\n",
      "sample 48\n",
      "sample 49\n",
      "sample 50\n",
      "sample 51\n",
      "sample 52\n",
      "sample 53\n",
      "sample 54\n",
      "sample 55\n",
      "sample 56\n",
      "sample 57\n",
      "sample 58\n",
      "sample 59\n",
      "sample 60\n",
      "sample 61\n",
      "sample 62\n",
      "sample 63\n",
      "sample 64\n",
      "sample 65\n",
      "sample 66\n",
      "sample 67\n",
      "sample 68\n",
      "sample 69\n",
      "sample 70\n",
      "sample 71\n",
      "sample 72\n",
      "sample 73\n",
      "sample 74\n",
      "sample 75\n",
      "sample 76\n",
      "sample 77\n",
      "sample 78\n",
      "sample 79\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#move all features with the same timestamp to one line \n",
    "\n",
    "for sample in range(len(train_input_data)):\n",
    "    matches = 0\n",
    "    print(f\"sample {sample}\")\n",
    "    timesteps = 0\n",
    "    for step in range(len(train_input_data[sample])):\n",
    "        if step != 0:\n",
    "            if train_input_data[sample][step-matches][0] == train_input_data[sample][step-1-matches][0]:\n",
    "                train_input_data[sample][step-1-matches].extend(train_input_data[sample][step-matches])\n",
    "                train_input_data[sample].pop(step-matches)\n",
    "                matches +=1\n",
    "            else:\n",
    "                timesteps+=1\n",
    "\n",
    "#pad input data\n",
    "max_timesteps = max(max([len(sample) for sample in train_input_data]), max([len(sample) for sample in train_gt_data]))\n",
    "max_features = max(max([len(feature) for sample in train_input_data for feature in sample]),max([len(feature) for sample in train_gt_data for feature in sample]))\n",
    "\n",
    "for sample in train_input_data:\n",
    "    sample.extend([[0]*max_features]*(max_timesteps-len(sample)))\n",
    "\n",
    "\n",
    "train_input_data_padded = [tf.keras.preprocessing.sequence.pad_sequences(sample,value=0, padding=\"post\", dtype=np.float64, maxlen=max_features) for sample in train_input_data]\n",
    "train_input_data_padded = np.array(train_input_data_padded)\n",
    "\n",
    "del train_input_data\n",
    "\n",
    "#pad ground truth data\n",
    "max_timesteps_gt = max_timesteps\n",
    "max_features_gt = max([len(feature) for sample in train_gt_data for feature in sample])\n",
    "\n",
    "for sample in train_gt_data:\n",
    "    sample.extend([[0]*max_features_gt]*(max_timesteps_gt-len(sample)))\n",
    "\n",
    "#convert to right data format\n",
    "train_gt_data_padded = [tf.keras.preprocessing.sequence.pad_sequences(sample, value=0,padding=\"post\", dtype=np.float64, maxlen=max_features_gt) for sample in train_gt_data]\n",
    "train_gt_data_padded = np.array(train_gt_data_padded)\n",
    "del train_gt_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as preprocess\n",
    "\n",
    "#normalize data\n",
    "scaler = preprocess.MinMaxScaler()\n",
    "train_input_data_padded_normalized = []\n",
    "for sample in train_input_data_padded:\n",
    "    data_range = []\n",
    "    train_input_data_padded_normalized.append(scaler.fit_transform(sample))\n",
    "train_input_data_padded_normalized=np.array(train_input_data_padded_normalized)\n",
    "\n",
    "train_gt_data_padded_normalized = []\n",
    "for sample in train_gt_data_padded:\n",
    "    data_range = []\n",
    "    train_gt_data_padded_normalized.append(scaler.fit_transform(sample))\n",
    "train_gt_data_padded_normalized=np.array(train_gt_data_padded_normalized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "clear_session()\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0, input_shape=(train_input_data_padded.shape[1], train_input_data_padded.shape[2])))\n",
    "#model.add(tf.keras.layers.BatchNormalization(axis=-1, input_shape=(train_input_data_padded.shape[1], train_input_data_padded.shape[2])))\n",
    "model.add(LSTM(500, return_sequences=True))\n",
    "model.add(Dense(7, activation=\"linear\"))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"MeanSquaredError\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 3141, 2067)\n",
      "(80, 3141, 7)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n",
      "[[[ 0.13080561 -0.10591459 -0.02379882 ...  0.23695007 -0.16982178\n",
      "    0.12289654]\n",
      "  [ 0.23292425 -0.25090894 -0.02940829 ...  0.36450648 -0.22904949\n",
      "    0.23885106]\n",
      "  [ 0.28631237 -0.2952764  -0.05667304 ...  0.54573005 -0.37407097\n",
      "    0.2750918 ]\n",
      "  ...\n",
      "  [ 0.3249194  -0.4081111   0.45217526 ...  0.03408051 -0.5454806\n",
      "    0.21005493]\n",
      "  [ 0.3249194  -0.4081111   0.45217517 ...  0.03408045 -0.5454806\n",
      "    0.21005496]\n",
      "  [ 0.3249194  -0.4081111   0.4521752  ...  0.03408039 -0.5454806\n",
      "    0.21005493]]]\n",
      "[[[0.99576724 0.00211218 0.11476906 ... 1.         0.66337243 0.99999919]\n",
      "  [0.99576724 0.00211218 0.11473767 ... 1.         0.66337571 0.99999919]\n",
      "  [0.99576722 0.00211218 0.11436106 ... 1.         0.66245823 0.99999919]\n",
      "  ...\n",
      "  [0.         1.         1.         ... 0.         0.         0.        ]\n",
      "  [0.         1.         1.         ... 0.         0.         0.        ]\n",
      "  [0.         1.         1.         ... 0.         0.         0.        ]]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3141</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2067</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3141</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,136,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3141</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,507</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3141\u001b[0m, \u001b[38;5;34m2067\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3141\u001b[0m, \u001b[38;5;34m500\u001b[0m)      │     \u001b[38;5;34m5,136,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3141\u001b[0m, \u001b[38;5;34m7\u001b[0m)        │         \u001b[38;5;34m3,507\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,139,507</span> (19.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,139,507\u001b[0m (19.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,139,507</span> (19.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,139,507\u001b[0m (19.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_input_data_padded_normalized.shape)\n",
    "print(train_gt_data_padded.shape)\n",
    "\n",
    "print(model.predict(train_input_data_padded_normalized[0:1]))\n",
    "print(train_gt_data_padded_normalized[0:1])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 23s/step - loss: 217486608225877348057088.0000 - val_loss: 149519183369527296524288.0000\n",
      "Epoch 2/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 23s/step - loss: 215783689120377506627584.0000 - val_loss: 149519183369527296524288.0000\n",
      "Epoch 3/1000\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:08\u001b[0m 26s/step - loss: 196675852650166985162752.0000"
     ]
    }
   ],
   "source": [
    "\n",
    "# train the model\n",
    "model.fit(train_input_data_padded_normalized, train_gt_data_padded, epochs=1000, batch_size=12, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
